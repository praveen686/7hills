{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19f370bd",
   "metadata": {},
   "source": "# S12 Intraday Options Evaluation Harness v2\n\n**Audit-grade** walk-forward evaluation of regime-conditional option strategies.\n\n**Key properties:**\n- Zero look-ahead: features at minute t use only data ≤ t; SANOS regime from previous day's EOD\n- Training label = actual spread payoff sign (not underlying return)\n- SANOS/fractional regime gating: vol cheap → debit, vol rich → credit, neutral → debit\n- Adverse execution: close-as-mid + parametric spread ticks\n- Liquidity gates: OI, volume, price minimums\n- Cost sensitivity sweep: ticks × fees grid\n- Feature ablation stability: 6 groups including SANOS + fractional\n- Regime-conditioned structures: debit spreads vs credit spreads\n\n**Data**: 316 days of 1-min OHLCV (nfo_1min), daily index close, no bid/ask."
  },
  {
   "cell_type": "code",
   "id": "b2e002cc",
   "metadata": {},
   "source": "\"\"\"Cell 1: Imports & DuckDB connection.\"\"\"\nimport sys, os\nsys.path.insert(0, \"/home/ubuntu/Desktop/7hills/QuantLaxmi\")\n\nimport duckdb\nimport numpy as np\nimport pandas as pd\nimport math\nimport time\nimport warnings\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List, Tuple, Optional\nfrom datetime import datetime, timedelta\nfrom functools import lru_cache\n\nfrom core.pricing.sanos import fit_sanos\nfrom core.pricing.risk_neutral import (\n    extract_density, compute_moments, shannon_entropy, kl_divergence, tail_weights,\n)\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nDATA_BASE = \"/home/ubuntu/Desktop/7hills/QuantLaxmi/data/market\"\ncon = duckdb.connect()\n\n# nfo_1min: option + futures tick data\ncon.execute(f\"\"\"\n    CREATE OR REPLACE VIEW nfo_1min AS\n    SELECT * FROM read_parquet(\n        '{DATA_BASE}/nfo_1min/*/*.parquet',\n        hive_partitioning=true, union_by_name=true)\n\"\"\")\n\n# nse_index_close: daily index values (needed for SANOS spot)\ncon.execute(f\"\"\"\n    CREATE OR REPLACE VIEW nse_index_close AS\n    SELECT * FROM read_parquet(\n        '{DATA_BASE}/nse_index_close/*/*.parquet',\n        hive_partitioning=true, hive_types_autocast=false, union_by_name=true)\n\"\"\")\n\n# Verify\nrow_count = con.execute(\"SELECT COUNT(*) FROM nfo_1min\").fetchone()[0]\nday_count = con.execute(\"SELECT COUNT(DISTINCT date) FROM nfo_1min\").fetchone()[0]\nidx_count = con.execute(\"SELECT COUNT(DISTINCT date) FROM nse_index_close\").fetchone()[0]\nprint(f\"nfo_1min: {row_count:,} rows, {day_count} days\")\nprint(f\"nse_index_close: {idx_count} days\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "582713ca",
   "metadata": {},
   "source": "\"\"\"Cell 2: Session constants and configuration.\"\"\"\n\nSESSION_START = \"09:15:00\"\nSESSION_MINUTES = 375       # 09:15..15:29\nSTRIKE_STEP = {\"NIFTY\": 50, \"BANKNIFTY\": 100}\nINDEX_NAME_MAP = {\"NIFTY\": \"Nifty 50\", \"BANKNIFTY\": \"Nifty Bank\"}\nNAME = \"NIFTY\"\n\n# Walk-forward config\nTRAIN_DAYS = 60\nTEST_DAYS = 10\nDECISION_STEP = 5           # minutes between candidate entries\nENTRY_MIN = 15              # 09:30 (15 min after open)\nEXIT_MIN = 330              # 14:45\nHOLD_MIN = 60               # 60-minute time stop\nSCORE_THRESHOLD = 0.5       # |score| must exceed this to trade\nWING_STEPS = 1              # OTM offset for short leg\n\n# Liquidity gates\nOI_MIN = 500\nVOL_MIN = 10\nPRICE_MIN = 2.0\n\n# Cost sensitivity grid: (spread_ticks, fees_bps)\nCOST_GRID = [\n    (1, 10.0), (2, 10.0), (3, 10.0),\n    (1, 20.0), (2, 20.0), (3, 20.0),\n    (5, 20.0), (8, 40.0),\n]\nTICK_SIZE = 0.05\n\n# ── SANOS regime thresholds ──\n# Entropy < threshold → vol cheap (subdiffusive, buy vol → debit spreads)\n# Entropy > threshold → vol rich (superdiffusive, sell vol → credit spreads)\nENTROPY_LOW = 3.5      # below → vol cheap\nENTROPY_HIGH = 4.5     # above → vol rich\nALPHA_SUBDIFFUSIVE = 1.8   # α < this → subdiffusive (mean-reverting)\nALPHA_SUPERDIFFUSIVE = 2.2 # α > this → superdiffusive (trending)\n\n# Feature groups for ablation\nFEATURE_GROUPS = {\n    \"momentum\":  {\"mom_5\", \"mom_15\", \"mom_30\"},\n    \"volatility\": {\"rv_30\", \"rv_120\", \"range_ratio\"},\n    \"trend\":     {\"slope_60\", \"slope_120\"},\n    \"volume\":    {\"vol_ratio\", \"oi_change_rate\"},\n    \"sanos\":     {\"sanos_skew\", \"sanos_entropy\", \"sanos_kl\", \"sanos_left_tail\"},\n    \"fractional\": {\"frac_alpha\", \"frac_rvd\"},\n}\n\n# Ablation scenarios\nABLATIONS = [\n    [],                          # baseline (all features)\n    [\"momentum\"],\n    [\"volatility\"],\n    [\"trend\"],\n    [\"volume\"],\n    [\"sanos\"],\n    [\"fractional\"],\n    [\"sanos\", \"fractional\"],\n    [\"momentum\", \"trend\"],\n]\n\nprint(f\"Config: {NAME}, train={TRAIN_DAYS}d, test={TEST_DAYS}d, \"\n      f\"hold={HOLD_MIN}m, step={DECISION_STEP}m\")\nprint(f\"Cost grid: {len(COST_GRID)} scenarios, Ablations: {len(ABLATIONS)} scenarios\")\nprint(f\"Total evaluation runs: {len(COST_GRID) * len(ABLATIONS)}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cfa68ce5",
   "metadata": {},
   "source": "\"\"\"Cell 3: Data access helpers — ALL option chain data preloaded into memory.\n\nKey optimization: load all option bars for each day into RAM once,\nthen all chain_at_minute / contract_at_minute calls are dict lookups.\nThis avoids 20K+ DuckDB queries during label precomputation and walk-forward.\n\"\"\"\n\ndef list_trading_days(con, name: str) -> List[str]:\n    df = con.execute(\"\"\"\n        SELECT DISTINCT CAST(date AS VARCHAR) AS d\n        FROM nfo_1min WHERE name = ? ORDER BY d\n    \"\"\", [name]).fetchdf()\n    return df[\"d\"].tolist()\n\n\ndef nearest_expiry(con, name: str, date_str: str, instrument_type: str) -> Optional[str]:\n    df = con.execute(\"\"\"\n        SELECT CAST(MIN(expiry) AS VARCHAR) AS e\n        FROM nfo_1min\n        WHERE name = ? AND date = ? AND instrument_type = ?\n    \"\"\", [name, date_str, instrument_type]).fetchdf()\n    e = df.loc[0, \"e\"] if len(df) and df.loc[0, \"e\"] is not None else None\n    return e\n\n\ndef fut_close_series(con, name: str, date_str: str) -> Optional[pd.DataFrame]:\n    \"\"\"All 1-min bars for nearest-expiry futures on a day, ordered by time.\"\"\"\n    e = nearest_expiry(con, name, date_str, \"FUT\")\n    if not e:\n        return None\n    df = con.execute(\"\"\"\n        SELECT open, high, low, close, volume, oi\n        FROM nfo_1min\n        WHERE name = ? AND date = ? AND instrument_type = 'FUT' AND expiry = ?\n    \"\"\", [name, date_str, e]).fetchdf()\n    if df.empty or len(df) < 30:\n        return None\n    return df.reset_index(drop=True)\n\n\n# ── Preload ALL option chain data into memory ──\n\ndef preload_option_chains(con, name, days):\n    \"\"\"Load all CE/PE option bars for nearest expiry into memory.\n\n    Returns:\n      chain_mem[day][right] = {strike: {\"symbol\": str, \"close\": np.array,\n                                         \"volume\": np.array, \"oi\": np.array}}\n      expiry_mem[day][right] = expiry string\n    \"\"\"\n    chain_mem = {}\n    expiry_mem = {}\n    t0 = time.time()\n\n    for i, d in enumerate(days):\n        chain_mem[d] = {}\n        expiry_mem[d] = {}\n        for right in [\"CE\", \"PE\"]:\n            exp = nearest_expiry(con, name, d, right)\n            if not exp:\n                continue\n            expiry_mem[d][right] = exp\n\n            df = con.execute(\"\"\"\n                SELECT strike, symbol, close, volume, oi\n                FROM nfo_1min\n                WHERE name = ? AND date = ? AND instrument_type = ? AND expiry = ?\n                ORDER BY strike\n            \"\"\", [name, d, right, exp]).fetchdf()\n\n            if df.empty:\n                continue\n\n            strikes = {}\n            for strike, grp in df.groupby(\"strike\"):\n                strikes[float(strike)] = {\n                    \"symbol\": str(grp[\"symbol\"].iloc[0]),\n                    \"close\": grp[\"close\"].values.astype(np.float64),\n                    \"volume\": grp[\"volume\"].values.astype(np.int64),\n                    \"oi\": grp[\"oi\"].values.astype(np.int64),\n                }\n            chain_mem[d][right] = strikes\n\n        if (i + 1) % 50 == 0:\n            print(f\"  Preloaded {i+1}/{len(days)} days ({time.time()-t0:.0f}s)\", flush=True)\n\n    print(f\"  Chain preload DONE: {len(chain_mem)} days in {time.time()-t0:.0f}s\")\n    return chain_mem, expiry_mem\n\n\n# ── In-memory chain access ──\n\ndef chain_at_minute_mem(chain_mem, day, right, minute_offset):\n    \"\"\"Get chain snapshot at a specific minute from preloaded data.\n    Returns DataFrame with columns: strike, close, volume, oi, symbol.\n    \"\"\"\n    if day not in chain_mem or right not in chain_mem[day]:\n        return pd.DataFrame()\n    strikes = chain_mem[day][right]\n    rows = []\n    for k, data in strikes.items():\n        idx = int(minute_offset)\n        if idx >= len(data[\"close\"]):\n            continue\n        rows.append({\n            \"strike\": k,\n            \"close\": float(data[\"close\"][idx]),\n            \"volume\": int(data[\"volume\"][idx]),\n            \"oi\": int(data[\"oi\"][idx]),\n            \"symbol\": data[\"symbol\"],\n        })\n    if not rows:\n        return pd.DataFrame()\n    return pd.DataFrame(rows).sort_values(\"strike\").reset_index(drop=True)\n\n\ndef contract_at_minute_mem(chain_mem, day, symbol, minute_offset):\n    \"\"\"Get single contract bar from preloaded data.\"\"\"\n    if day not in chain_mem:\n        return None\n    for right in [\"CE\", \"PE\"]:\n        if right not in chain_mem[day]:\n            continue\n        for k, data in chain_mem[day][right].items():\n            if data[\"symbol\"] == symbol:\n                idx = int(minute_offset)\n                if idx >= len(data[\"close\"]):\n                    return None\n                return {\n                    \"close\": float(data[\"close\"][idx]),\n                    \"volume\": int(data[\"volume\"][idx]),\n                    \"oi\": int(data[\"oi\"][idx]),\n                }\n    return None\n\n\n# ── Execute preload ──\ndays = list_trading_days(con, NAME)\nprint(f\"Trading days: {len(days)} ({days[0]} -> {days[-1]})\")\n\nprint(\"Preloading option chain data into memory...\")\nchain_mem, expiry_mem = preload_option_chains(con, NAME, days)\n\nsample_fut = fut_close_series(con, NAME, days[-1])\nprint(f\"Sample futures bars ({days[-1]}): {len(sample_fut)} bars\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3em7qje1ebm",
   "source": "\"\"\"Cell 3b: SANOS + fractional regime precomputation.\n\nFor each day, calibrate SANOS from PREVIOUS day's EOD option chain (causal).\nCompute fractional diffusion exponent from cumulative daily returns.\nBuild regime cache: dict[date] -> {sanos features, alpha, regime_class}.\n\nregime_class:\n  \"vol_cheap\"  → low entropy + subdiffusive → BUY vol → debit spreads\n  \"vol_rich\"   → high entropy + superdiffusive → SELL vol → credit spreads\n  \"neutral\"    → ambiguous → debit spreads (safer default)\n\"\"\"\n\n# ── Fractional diffusion estimators ──\n\ndef estimate_alpha_msd(returns, max_lag=50):\n    \"\"\"MSD scaling: MSD(τ) ~ τ^{2H}, α = 2H.\"\"\"\n    cumret = np.cumsum(returns)\n    n = len(cumret)\n    max_lag = min(max_lag, n // 3)\n    if max_lag < 4:\n        return 1.0\n    lags = np.arange(2, max_lag + 1)\n    msds = np.empty(len(lags))\n    for i, tau in enumerate(lags):\n        displacements = cumret[tau:] - cumret[:-tau]\n        msds[i] = np.mean(displacements**2)\n    valid = msds > 0\n    if valid.sum() < 3:\n        return 1.0\n    log_lags = np.log(lags[valid])\n    log_msds = np.log(msds[valid])\n    slope, _ = np.polyfit(log_lags, log_msds, 1)\n    hurst = np.clip(slope / 2.0, 0.01, 1.5)\n    return float(2.0 * hurst)\n\n\ndef estimate_alpha_waiting(returns, threshold=0.0):\n    \"\"\"Hill estimator from waiting-time distribution.\"\"\"\n    if threshold <= 0:\n        threshold = np.std(returns, ddof=1) * 0.5 if len(returns) > 2 else 1e-8\n    exceedance_idx = np.where(np.abs(returns) > threshold)[0]\n    if len(exceedance_idx) < 10:\n        return 1.0\n    waiting_times = np.diff(exceedance_idx).astype(float)\n    waiting_times = waiting_times[waiting_times > 0]\n    if len(waiting_times) < 5:\n        return 1.0\n    sorted_wt = np.sort(waiting_times)[::-1]\n    k = max(int(len(sorted_wt) * 0.1), 5)\n    k = min(k, len(sorted_wt) - 1)\n    log_ratios = np.log(sorted_wt[:k]) - np.log(sorted_wt[k])\n    if np.sum(log_ratios) == 0:\n        return 1.0\n    return float(np.clip(k / np.sum(log_ratios), 0.1, 3.0))\n\n\ndef estimate_alpha(returns, max_lag=50):\n    \"\"\"Consensus: 0.6 × MSD + 0.4 × waiting-time.\"\"\"\n    return 0.6 * estimate_alpha_msd(returns, max_lag) + 0.4 * estimate_alpha_waiting(returns)\n\n\ndef ramanujan_volatility_distortion(vol, alpha=0.2, depth=20):\n    \"\"\"Continued-fraction volatility transform R(V).\"\"\"\n    cf = 1.0\n    for k in range(depth, 0, -1):\n        cf = 1.0 + k * vol / max(cf, 1e-30)\n    return math.exp(-alpha * vol) / max(cf, 1e-30)\n\n\n# ── SANOS chain builder from 1-min data ──\n\ndef prepare_chain_from_1min(con, symbol, d, max_expiries=2):\n    \"\"\"Build SANOS-ready option chain from nfo_1min last-bar snapshot.\"\"\"\n    df = con.execute(\"\"\"\n        SELECT strike, instrument_type, expiry,\n               LAST(close) AS close, LAST(oi) AS oi\n        FROM nfo_1min\n        WHERE date = ? AND name = ? AND instrument_type IN ('CE', 'PE')\n        GROUP BY strike, instrument_type, expiry\n        ORDER BY expiry, strike\n    \"\"\", [d, symbol]).fetchdf()\n\n    if df is None or len(df) < 20:\n        return None\n\n    # Spot from index close or futures fallback\n    idx_name = INDEX_NAME_MAP.get(symbol, symbol)\n    try:\n        spot_df = con.execute(\n            'SELECT \"Closing Index Value\" AS spot FROM nse_index_close '\n            'WHERE \"Index Name\" = ? AND date = ?', [idx_name, d]\n        ).fetchdf()\n        if not spot_df.empty and spot_df[\"spot\"].iloc[0] is not None:\n            spot = float(spot_df[\"spot\"].iloc[0])\n        else:\n            fut_df = con.execute(\n                \"SELECT LAST(close) AS c FROM nfo_1min \"\n                \"WHERE name = ? AND date = ? AND instrument_type = 'FUT' \"\n                \"AND expiry = (SELECT MIN(expiry) FROM nfo_1min \"\n                \"WHERE name = ? AND date = ? AND instrument_type = 'FUT')\",\n                [symbol, d, symbol, d]\n            ).fetchdf()\n            if fut_df.empty:\n                return None\n            spot = float(fut_df[\"c\"].iloc[0])\n    except Exception:\n        return None\n\n    expiries = sorted(df[\"expiry\"].unique())[:max_expiries]\n    market_strikes_list, market_calls_list, atm_vars, expiry_labels = [], [], [], []\n\n    for exp in expiries:\n        sub = df[df[\"expiry\"] == exp].copy()\n        calls = sub[sub[\"instrument_type\"] == \"CE\"].set_index(\"strike\")[\"close\"]\n        puts = sub[sub[\"instrument_type\"] == \"PE\"].set_index(\"strike\")[\"close\"]\n        common = sorted(set(calls.index) & set(puts.index))\n        if len(common) < 10:\n            continue\n\n        best_F, best_diff = spot, float(\"inf\")\n        for K in common:\n            C, P = float(calls[K]), float(puts[K])\n            if C <= 0 or P <= 0:\n                continue\n            F = K + C - P\n            diff = abs(C - P)\n            if diff < best_diff:\n                best_diff = diff\n                best_F = F\n        forward = best_F\n\n        rows = []\n        for K in common:\n            C_val, P_val = float(calls[K]), float(puts[K])\n            k_norm = K / forward\n            if K >= forward:\n                c_norm = C_val / forward\n                if c_norm > 0.001:\n                    rows.append((k_norm, c_norm))\n            else:\n                c_norm = P_val / forward + 1.0 - k_norm\n                if c_norm > 0.001:\n                    rows.append((k_norm, c_norm))\n\n        if len(rows) < 5:\n            continue\n        rows.sort(key=lambda x: x[0])\n        k_arr = np.array([r[0] for r in rows])\n        c_arr = np.array([r[1] for r in rows])\n\n        atm_K = min(common, key=lambda K: abs(K - forward))\n        straddle = float(calls[atm_K]) + float(puts[atm_K])\n        straddle_norm = straddle / forward\n        atm_var = max((straddle_norm / 2.0 * math.sqrt(2.0 * math.pi)) ** 2, 1e-6)\n\n        market_strikes_list.append(k_arr)\n        market_calls_list.append(c_arr)\n        atm_vars.append(atm_var)\n        expiry_labels.append(str(exp))\n\n    if not market_strikes_list:\n        return None\n    return {\n        \"market_strikes\": market_strikes_list,\n        \"market_calls\": market_calls_list,\n        \"atm_variances\": np.array(atm_vars),\n        \"expiry_labels\": expiry_labels,\n        \"forward\": forward,\n        \"spot\": spot,\n    }\n\n\n# ── Calibrate SANOS for all dates ──\n\ndef calibrate_sanos_daily(con, symbol, dates):\n    \"\"\"SANOS calibration per date. Returns dict[date] -> features.\"\"\"\n    cache = {}\n    prev_density, prev_K = None, None\n    ok_count, fail_count = 0, 0\n    t0 = time.time()\n\n    for i, d in enumerate(dates):\n        chain = prepare_chain_from_1min(con, symbol, d, max_expiries=2)\n        if chain is None:\n            fail_count += 1\n            continue\n        try:\n            result = fit_sanos(\n                market_strikes=chain[\"market_strikes\"],\n                market_calls=chain[\"market_calls\"],\n                atm_variances=chain[\"atm_variances\"],\n                expiry_labels=chain[\"expiry_labels\"],\n                eta=0.50, n_model_strikes=80,\n            )\n        except Exception:\n            fail_count += 1\n            continue\n        if not result.lp_success:\n            fail_count += 1\n            continue\n\n        K, q = extract_density(result, 0)\n        dK = K[1] - K[0]\n        mu, var, skew, kurt = compute_moments(K, q)\n        std = math.sqrt(max(var, 1e-14))\n        H = shannon_entropy(q, dK)\n        lt, rt = tail_weights(K, q, mu, std)\n\n        kl = 0.0\n        if prev_density is not None and prev_K is not None:\n            prev_q_interp = np.interp(K, prev_K, prev_density)\n            prev_q_interp = np.maximum(prev_q_interp, 0)\n            total_prev = np.sum(prev_q_interp) * dK\n            if total_prev > 1e-12:\n                prev_q_interp /= total_prev\n            kl = kl_divergence(q, prev_q_interp, dK)\n\n        cache[d] = {\n            \"skew\": skew, \"kurtosis\": kurt,\n            \"left_tail\": lt, \"right_tail\": rt,\n            \"entropy\": H, \"kl\": kl,\n            \"forward\": chain[\"forward\"],\n        }\n        prev_density, prev_K = q, K\n        ok_count += 1\n\n        if (i + 1) % 50 == 0:\n            print(f\"  SANOS {i+1}/{len(dates)}: {ok_count} ok, {fail_count} fail \"\n                  f\"({time.time()-t0:.0f}s)\")\n\n    print(f\"  SANOS DONE: {ok_count}/{len(dates)} calibrated in {time.time()-t0:.0f}s\")\n    return cache\n\n\n# ── Build regime cache ──\n\ndef build_regime_cache(sanos_cache, daily_closes, days):\n    \"\"\"Combine SANOS + fractional alpha into regime classification per day.\n\n    CAUSAL: regime for day i uses SANOS from day i-1 (EOD chain)\n    and fractional alpha from daily returns up to day i-1.\n    \"\"\"\n    regime_cache = {}\n\n    # Daily log returns for fractional alpha\n    daily_rets = []\n    for i, d in enumerate(days):\n        if i == 0:\n            daily_rets.append(0.0)\n            continue\n        c_prev = daily_closes.get(days[i-1])\n        c_curr = daily_closes.get(d)\n        if c_prev and c_curr and c_prev > 0 and c_curr > 0:\n            daily_rets.append(math.log(c_curr / c_prev))\n        else:\n            daily_rets.append(0.0)\n\n    for i, d in enumerate(days):\n        prev_d = days[i-1] if i > 0 else None\n\n        # SANOS features from previous day (causal)\n        sanos = sanos_cache.get(prev_d, {}) if prev_d else {}\n        entropy = sanos.get(\"entropy\", float(\"nan\"))\n        skew = sanos.get(\"skew\", 0.0)\n        kl = sanos.get(\"kl\", 0.0)\n        left_tail = sanos.get(\"left_tail\", 0.0)\n\n        # Fractional alpha from returns up to previous day\n        rets_so_far = np.array(daily_rets[1:i] if i > 1 else [0.0])\n        alpha = estimate_alpha(rets_so_far) if len(rets_so_far) >= 20 else 2.0\n        rv = np.std(rets_so_far[-30:], ddof=1) if len(rets_so_far) >= 30 else 0.0\n        rvd = ramanujan_volatility_distortion(rv) if rv > 0 else 0.5\n\n        # Regime classification\n        if np.isfinite(entropy) and entropy < ENTROPY_LOW and alpha < ALPHA_SUBDIFFUSIVE:\n            regime_class = \"vol_cheap\"   # debit spreads\n        elif np.isfinite(entropy) and entropy > ENTROPY_HIGH and alpha > ALPHA_SUPERDIFFUSIVE:\n            regime_class = \"vol_rich\"    # credit spreads\n        else:\n            regime_class = \"neutral\"     # default debit\n\n        regime_cache[d] = {\n            \"sanos_skew\": skew,\n            \"sanos_entropy\": entropy if np.isfinite(entropy) else 0.0,\n            \"sanos_kl\": kl,\n            \"sanos_left_tail\": left_tail,\n            \"frac_alpha\": alpha,\n            \"frac_rvd\": rvd,\n            \"regime_class\": regime_class,\n        }\n\n    return regime_cache\n\n\n# ── Execute precomputation ──\nprint(\"Calibrating SANOS across all trading days...\")\ndays = list_trading_days(con, NAME)\nsanos_cache = calibrate_sanos_daily(con, NAME, days)\n\n# Daily closes for fractional alpha\ndaily_closes = {}\nfor d in days:\n    fut = fut_close_series(con, NAME, d)\n    if fut is not None and not fut.empty:\n        daily_closes[d] = float(fut.iloc[-1][\"close\"])\n\nregime_cache = build_regime_cache(sanos_cache, daily_closes, days)\n\n# Summary\nregime_counts = {}\nfor v in regime_cache.values():\n    rc = v[\"regime_class\"]\n    regime_counts[rc] = regime_counts.get(rc, 0) + 1\nprint(f\"\\nRegime distribution: {regime_counts}\")\nprint(f\"SANOS features available for {len(sanos_cache)}/{len(days)} days\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bac16e75",
   "metadata": {},
   "source": [
    "\"\"\"Cell 4: Execution model — OHLC close-as-mid + parametric spread.\"\"\"\n",
    "\n",
    "def fill_from_close(side: str, close_px: float, spread_ticks: int, tick_size: float) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    OHLC-only execution: treat close as mid proxy.\n",
    "    BUY fills at close + spread_ticks * tick_size (adverse).\n",
    "    SELL fills at close - spread_ticks * tick_size (adverse).\n",
    "    \"\"\"\n",
    "    if close_px is None or not np.isfinite(close_px) or close_px <= 0:\n",
    "        return None\n",
    "    if side == \"BUY\":\n",
    "        return float(close_px + spread_ticks * tick_size)\n",
    "    else:\n",
    "        return float(close_px - spread_ticks * tick_size)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Leg:\n",
    "    symbol: str\n",
    "    side: str   # BUY or SELL\n",
    "    qty: int\n",
    "\n",
    "\n",
    "def structure_pnl(\n",
    "    legs: List[Leg],\n",
    "    entry_close: Dict[str, float],\n",
    "    exit_close: Dict[str, float],\n",
    "    spread_ticks: int,\n",
    "    tick_size: float,\n",
    "    fees_bps: float\n",
    ") -> Optional[Dict[str, float]]:\n",
    "    \"\"\"Compute multi-leg PnL from OHLC closes with adverse spread + fees.\"\"\"\n",
    "    entry_cash = 0.0\n",
    "    exit_cash = 0.0\n",
    "    turnover = 0.0\n",
    "\n",
    "    for leg in legs:\n",
    "        e_c = entry_close.get(leg.symbol)\n",
    "        x_c = exit_close.get(leg.symbol)\n",
    "        if e_c is None or x_c is None:\n",
    "            return None\n",
    "\n",
    "        e_px = fill_from_close(leg.side, e_c, spread_ticks, tick_size)\n",
    "        exit_side = \"SELL\" if leg.side == \"BUY\" else \"BUY\"\n",
    "        x_px = fill_from_close(exit_side, x_c, spread_ticks, tick_size)\n",
    "        if e_px is None or x_px is None:\n",
    "            return None\n",
    "\n",
    "        entry_cash += (+1 if leg.side == \"SELL\" else -1) * leg.qty * e_px\n",
    "        exit_cash  += (+1 if exit_side == \"SELL\" else -1) * leg.qty * x_px\n",
    "        turnover += abs(leg.qty) * 0.5 * (abs(e_px) + abs(x_px))\n",
    "\n",
    "    gross = entry_cash + exit_cash\n",
    "    fees = (fees_bps / 1e4) * turnover\n",
    "    net = gross - fees\n",
    "    return {\"gross\": gross, \"net\": net, \"turnover\": turnover, \"fees\": fees}\n",
    "\n",
    "\n",
    "print(\"Execution model ready\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "06c6c030",
   "metadata": {},
   "source": "\"\"\"Cell 5: Spread selectors — debit AND credit — with liquidity gates.\n\nAll chain access uses in-memory preloaded data (chain_mem).\n\"\"\"\n\n@dataclass\nclass SpreadSpec:\n    expiry: str\n    right: str\n    k_long: float\n    k_short: float\n    sym_long: str\n    sym_short: str\n    risk_capital: float   # debit paid (debit) or max loss (credit)\n    structure: str        # \"debit\" or \"credit\"\n\n\ndef pick_atm_debit_spread(\n    snap: pd.DataFrame, spot: float, right: str, step: int,\n    wing_steps: int = 1, oi_min: int = 500, vol_min: int = 10, price_min: float = 2.0\n) -> Optional[SpreadSpec]:\n    \"\"\"Debit spread: buy ATM, sell OTM wing.\"\"\"\n    if snap.empty:\n        return None\n    df = snap[(snap[\"oi\"] >= oi_min) & (snap[\"volume\"] >= vol_min) & (snap[\"close\"] >= price_min)]\n    if df.empty:\n        return None\n\n    atm = round(spot / step) * step\n    df = df.copy()\n    df[\"dist\"] = (df[\"strike\"] - atm).abs()\n    atm_row = df.sort_values(\"dist\").head(1)\n    if atm_row.empty:\n        return None\n\n    k_atm = float(atm_row[\"strike\"].iloc[0])\n    sym_atm = str(atm_row[\"symbol\"].iloc[0])\n    px_atm = float(atm_row[\"close\"].iloc[0])\n\n    k_wing = k_atm + wing_steps * step if right == \"CE\" else k_atm - wing_steps * step\n    wing_row = df[df[\"strike\"] == k_wing].head(1)\n    if wing_row.empty:\n        return None\n\n    sym_wing = str(wing_row[\"symbol\"].iloc[0])\n    px_wing = float(wing_row[\"close\"].iloc[0])\n    debit = max(1e-6, px_atm - px_wing)\n\n    return SpreadSpec(\n        expiry=\"\", right=right,\n        k_long=k_atm, k_short=k_wing,\n        sym_long=sym_atm, sym_short=sym_wing,\n        risk_capital=debit, structure=\"debit\",\n    )\n\n\ndef pick_atm_credit_spread(\n    snap: pd.DataFrame, spot: float, right: str, step: int,\n    wing_steps: int = 1, oi_min: int = 500, vol_min: int = 10, price_min: float = 2.0\n) -> Optional[SpreadSpec]:\n    \"\"\"Credit spread: sell ATM, buy OTM wing for protection.\"\"\"\n    if snap.empty:\n        return None\n    df = snap[(snap[\"oi\"] >= oi_min) & (snap[\"volume\"] >= vol_min) & (snap[\"close\"] >= price_min)]\n    if df.empty:\n        return None\n\n    atm = round(spot / step) * step\n    df = df.copy()\n    df[\"dist\"] = (df[\"strike\"] - atm).abs()\n    atm_row = df.sort_values(\"dist\").head(1)\n    if atm_row.empty:\n        return None\n\n    k_atm = float(atm_row[\"strike\"].iloc[0])\n    sym_atm = str(atm_row[\"symbol\"].iloc[0])\n    px_atm = float(atm_row[\"close\"].iloc[0])\n\n    k_wing = k_atm + wing_steps * step if right == \"CE\" else k_atm - wing_steps * step\n    wing_row = df[df[\"strike\"] == k_wing].head(1)\n    if wing_row.empty:\n        return None\n\n    sym_wing = str(wing_row[\"symbol\"].iloc[0])\n    px_wing = float(wing_row[\"close\"].iloc[0])\n    credit = max(1e-6, px_atm - px_wing)\n    wing_width = abs(k_atm - k_wing)\n    max_loss = max(1e-6, wing_width - credit)\n\n    return SpreadSpec(\n        expiry=\"\", right=right,\n        k_long=k_atm, k_short=k_wing,\n        sym_long=sym_atm, sym_short=sym_wing,\n        risk_capital=max_loss, structure=\"credit\",\n    )\n\n\ndef build_spread_trade_mem(\n    chain_mem, expiry_mem, name, date_str, t, spot, score, regime_class,\n    threshold, wing_steps, oi_min, vol_min, price_min\n):\n    \"\"\"Score + regime → directional spread. All data from memory.\"\"\"\n    if abs(score) < threshold:\n        return None\n\n    right = \"CE\" if score > 0 else \"PE\"\n    expiry = expiry_mem.get(date_str, {}).get(right)\n    if not expiry:\n        return None\n\n    step = STRIKE_STEP.get(name, 50)\n    snap = chain_at_minute_mem(chain_mem, date_str, right, t)\n\n    if regime_class == \"vol_rich\":\n        spec = pick_atm_credit_spread(\n            snap=snap, spot=spot, right=right, step=step,\n            wing_steps=wing_steps, oi_min=oi_min, vol_min=vol_min, price_min=price_min\n        )\n    else:\n        spec = pick_atm_debit_spread(\n            snap=snap, spot=spot, right=right, step=step,\n            wing_steps=wing_steps, oi_min=oi_min, vol_min=vol_min, price_min=price_min\n        )\n    if spec is None:\n        return None\n    spec.expiry = expiry\n\n    if spec.structure == \"debit\":\n        legs = [\n            Leg(symbol=spec.sym_long, side=\"BUY\", qty=1),\n            Leg(symbol=spec.sym_short, side=\"SELL\", qty=1),\n        ]\n    else:\n        legs = [\n            Leg(symbol=spec.sym_long, side=\"SELL\", qty=1),\n            Leg(symbol=spec.sym_short, side=\"BUY\", qty=1),\n        ]\n\n    return legs, float(spec.risk_capital), spec.structure\n\n\nprint(\"Spread selectors ready (debit + credit, in-memory)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9ee20c7",
   "metadata": {},
   "source": "\"\"\"Cell 6: Causal intraday feature builder with SANOS/fractional regime features.\n\nUses only data up to minute t for intraday features.\nSANOS/fractional features are from previous day's EOD (causal via regime_cache).\n\"\"\"\n\ndef build_features_upto(ul_df: pd.DataFrame, day: str = None) -> Optional[Dict[str, float]]:\n    \"\"\"Build intraday + regime features from futures bars up to current row.\"\"\"\n    n = len(ul_df)\n    if n < 30:\n        return None\n\n    c = ul_df[\"close\"].values.astype(float)\n    v = ul_df[\"volume\"].values.astype(float)\n    oi = ul_df[\"oi\"].values.astype(float)\n    rets = np.diff(np.log(np.maximum(c, 1e-8)))\n    if len(rets) < 5:\n        return None\n\n    feat = {}\n\n    # ── Momentum features ──\n    feat[\"mom_5\"]  = float((c[-1] / c[-6] - 1.0) if n >= 6 else 0.0)\n    feat[\"mom_15\"] = float((c[-1] / c[-16] - 1.0) if n >= 16 else 0.0)\n    feat[\"mom_30\"] = float((c[-1] / c[-31] - 1.0) if n >= 31 else 0.0)\n\n    # ── Volatility features ──\n    feat[\"rv_30\"] = float(np.std(rets[-30:], ddof=1) * np.sqrt(375)) if len(rets) >= 30 else np.nan\n    feat[\"rv_120\"] = float(np.std(rets[-120:], ddof=1) * np.sqrt(375)) if len(rets) >= 120 else np.nan\n    if n >= 30:\n        h = ul_df[\"high\"].values[-30:].astype(float) if \"high\" in ul_df.columns else c[-30:]\n        l = ul_df[\"low\"].values[-30:].astype(float) if \"low\" in ul_df.columns else c[-30:]\n        ranges = h - l\n        mean_range = np.mean(ranges)\n        feat[\"range_ratio\"] = float(ranges[-1] / mean_range) if mean_range > 0 else 1.0\n    else:\n        feat[\"range_ratio\"] = np.nan\n\n    # ── Trend features ──\n    if n >= 60:\n        x = np.arange(60, dtype=float)\n        y = c[-60:]\n        slope, _ = np.polyfit(x, y, 1)\n        feat[\"slope_60\"] = float(slope / c[-1]) if c[-1] > 0 else 0.0\n    else:\n        feat[\"slope_60\"] = np.nan\n    if n >= 120:\n        x = np.arange(120, dtype=float)\n        y = c[-120:]\n        slope, _ = np.polyfit(x, y, 1)\n        feat[\"slope_120\"] = float(slope / c[-1]) if c[-1] > 0 else 0.0\n    else:\n        feat[\"slope_120\"] = np.nan\n\n    # ── Volume features ──\n    if n >= 30:\n        v_recent = v[-5:]\n        v_hist = v[-30:-5]\n        feat[\"vol_ratio\"] = float(np.mean(v_recent) / max(np.mean(v_hist), 1.0))\n    else:\n        feat[\"vol_ratio\"] = np.nan\n    if n >= 15:\n        feat[\"oi_change_rate\"] = float((oi[-1] - oi[-15]) / max(oi[-15], 1.0))\n    else:\n        feat[\"oi_change_rate\"] = np.nan\n\n    # ── SANOS regime features (from previous day, causal) ──\n    if day and day in regime_cache:\n        rc = regime_cache[day]\n        feat[\"sanos_skew\"] = rc[\"sanos_skew\"]\n        feat[\"sanos_entropy\"] = rc[\"sanos_entropy\"]\n        feat[\"sanos_kl\"] = rc[\"sanos_kl\"]\n        feat[\"sanos_left_tail\"] = rc[\"sanos_left_tail\"]\n        feat[\"frac_alpha\"] = rc[\"frac_alpha\"]\n        feat[\"frac_rvd\"] = rc[\"frac_rvd\"]\n    else:\n        feat[\"sanos_skew\"] = np.nan\n        feat[\"sanos_entropy\"] = np.nan\n        feat[\"sanos_kl\"] = np.nan\n        feat[\"sanos_left_tail\"] = np.nan\n        feat[\"frac_alpha\"] = np.nan\n        feat[\"frac_rvd\"] = np.nan\n\n    return feat\n\n\ndef ablate_feat(feat: Dict[str, float], drop_groups: List[str]) -> Dict[str, float]:\n    \"\"\"Remove features belonging to dropped groups.\"\"\"\n    drop_keys = set()\n    for g in drop_groups:\n        drop_keys |= FEATURE_GROUPS.get(g, set())\n    return {k: v for k, v in feat.items() if k not in drop_keys}\n\n\nprint(\"Feature builder ready (15 features, 6 groups: momentum, volatility, trend, volume, sanos, fractional)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "84c16f22",
   "metadata": {},
   "source": "\"\"\"Cell 7: Spread payoff label + ridge linear classifier.\n\nLabel = sign of actual CE spread payoff over hold period.\n  +1 → CE spread profitable → bullish signal\n  -1 → CE spread not profitable → bearish signal\n\nAll chain access via in-memory preloaded data (chain_mem).\n\"\"\"\n\ndef label_spread_payoff_mem(\n    chain_mem, expiry_mem, name, date_str, t, hold, spot, regime_class,\n    wing_steps, oi_min, vol_min, price_min, tick_size\n):\n    \"\"\"Compute actual CE spread payoff sign at (day, t). In-memory.\"\"\"\n    t_exit = min(t + hold, EXIT_MIN)\n    if t_exit <= t:\n        return None\n\n    right = \"CE\"\n    expiry = expiry_mem.get(date_str, {}).get(right)\n    if not expiry:\n        return None\n\n    step = STRIKE_STEP.get(name, 50)\n    snap = chain_at_minute_mem(chain_mem, date_str, right, t)\n    if snap.empty:\n        return None\n\n    if regime_class == \"vol_rich\":\n        spec = pick_atm_credit_spread(\n            snap=snap, spot=spot, right=right, step=step,\n            wing_steps=wing_steps, oi_min=oi_min, vol_min=vol_min, price_min=price_min\n        )\n    else:\n        spec = pick_atm_debit_spread(\n            snap=snap, spot=spot, right=right, step=step,\n            wing_steps=wing_steps, oi_min=oi_min, vol_min=vol_min, price_min=price_min\n        )\n    if spec is None:\n        return None\n\n    exit_long = contract_at_minute_mem(chain_mem, date_str, spec.sym_long, t_exit)\n    exit_short = contract_at_minute_mem(chain_mem, date_str, spec.sym_short, t_exit)\n    if exit_long is None or exit_short is None:\n        return None\n\n    entry_long_row = snap[snap[\"symbol\"] == spec.sym_long]\n    entry_short_row = snap[snap[\"symbol\"] == spec.sym_short]\n    if entry_long_row.empty or entry_short_row.empty:\n        return None\n\n    entry_close = {spec.sym_long: float(entry_long_row[\"close\"].iloc[0]),\n                   spec.sym_short: float(entry_short_row[\"close\"].iloc[0])}\n    exit_close = {spec.sym_long: exit_long[\"close\"],\n                  spec.sym_short: exit_short[\"close\"]}\n\n    if spec.structure == \"debit\":\n        legs = [Leg(symbol=spec.sym_long, side=\"BUY\", qty=1),\n                Leg(symbol=spec.sym_short, side=\"SELL\", qty=1)]\n    else:\n        legs = [Leg(symbol=spec.sym_long, side=\"SELL\", qty=1),\n                Leg(symbol=spec.sym_short, side=\"BUY\", qty=1)]\n\n    pnl = structure_pnl(legs, entry_close, exit_close,\n                        spread_ticks=0, tick_size=tick_size, fees_bps=0.0)\n    if pnl is None:\n        return None\n\n    return 1 if pnl[\"gross\"] > 0 else -1\n\n\nclass RidgeLinearModel:\n    \"\"\"Minimal ridge classifier.\"\"\"\n    def __init__(self, w: np.ndarray, b: float, keys: List[str]):\n        self.w = w\n        self.b = b\n        self.keys = keys\n\n    def predict_score(self, feat: Dict[str, float]) -> float:\n        x = np.array([feat.get(k, 0.0) if np.isfinite(feat.get(k, 0.0)) else 0.0\n                       for k in self.keys], dtype=float)\n        return float(np.dot(self.w, x) + self.b)\n\n\ndef fit_ridge(X: List[Dict[str, float]], y: List[int], l2: float = 1.0) -> RidgeLinearModel:\n    \"\"\"Fit ridge linear model. Standardizes features on train data only.\"\"\"\n    keys = sorted({k for d in X for k in d.keys()})\n    M = len(X)\n    D = len(keys)\n    A = np.zeros((M, D), dtype=float)\n    for i, d in enumerate(X):\n        for j, k in enumerate(keys):\n            v = d.get(k, 0.0)\n            A[i, j] = v if np.isfinite(v) else 0.0\n    yy = np.array(y, dtype=float)\n\n    mu = A.mean(axis=0)\n    sd = A.std(axis=0)\n    sd[sd < 1e-9] = 1.0\n    Z = (A - mu) / sd\n\n    w = np.linalg.solve(Z.T @ Z + l2 * np.eye(D), Z.T @ yy)\n    b = float(yy.mean())\n\n    w_scaled = w / sd\n    b_scaled = b - float(np.dot(w_scaled, mu))\n    return RidgeLinearModel(w_scaled, b_scaled, keys)\n\n\nprint(\"Spread payoff label + model ready (in-memory)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e38b8cb8",
   "metadata": {},
   "source": "\"\"\"Cell 8: SANOS-driven regime labeling (causal, from regime_cache).\"\"\"\n\ndef regime_label(day: str) -> str:\n    \"\"\"Get regime class for a given day from precomputed SANOS/fractional cache.\"\"\"\n    if day in regime_cache:\n        return regime_cache[day][\"regime_class\"]\n    return \"neutral\"\n\n\ndef regime_detail(day: str) -> str:\n    \"\"\"Detailed regime string for reporting.\"\"\"\n    if day not in regime_cache:\n        return \"unknown\"\n    rc = regime_cache[day]\n    cls = rc[\"regime_class\"]\n    ent = rc[\"sanos_entropy\"]\n    alpha = rc[\"frac_alpha\"]\n    return f\"{cls}(ent={ent:.2f},α={alpha:.2f})\"\n\n\nprint(\"SANOS-driven regime labeling ready\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5f4dd0db",
   "metadata": {},
   "source": [
    "\"\"\"Cell 9: Decision time grid.\"\"\"\n",
    "\n",
    "def decision_times(step=5, start_min=15, end_min=330) -> List[int]:\n",
    "    \"\"\"Minute offsets from session open (09:15) for candidate entries.\"\"\"\n",
    "    return list(range(start_min, end_min + 1, step))\n",
    "\n",
    "\n",
    "dt = decision_times(step=DECISION_STEP, start_min=ENTRY_MIN, end_min=EXIT_MIN)\n",
    "print(f\"Decision times: {len(dt)} per day (every {DECISION_STEP}m, \"\n",
    "      f\"{ENTRY_MIN}m..{EXIT_MIN}m from open)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac853c69",
   "metadata": {},
   "source": "\"\"\"Cell 10: Walk-forward intraday options backtest — regime-conditional.\n\nAll chain access via in-memory preloaded data (chain_mem).\nLabel = actual spread payoff sign. Structure = debit/credit per regime.\n\"\"\"\n\ndef walkforward_intraday(\n    con, chain_mem, expiry_mem, name, days,\n    train_days, test_days,\n    step, entry_min, exit_min, hold_min,\n    threshold, wing_steps,\n    oi_min, vol_min, price_min,\n    tick_size,\n    cost_grid, ablations,\n):\n    results = {}\n\n    # ── Preload futures bars ──\n    print(\"Preloading futures bars...\", end=\" \", flush=True)\n    t0 = time.time()\n    fut_cache = {}\n    for d in days:\n        fut_cache[d] = fut_close_series(con, name, d)\n    print(f\"{len(fut_cache)} days in {time.time()-t0:.1f}s\")\n\n    dt_grid = decision_times(step=step, start_min=entry_min, end_min=exit_min)\n\n    # ── Precompute spread payoff labels (in-memory, fast) ──\n    print(\"Precomputing spread payoff labels...\", end=\" \", flush=True)\n    t0_labels = time.time()\n    label_cache = {}\n    label_ok, label_fail = 0, 0\n\n    for d in days:\n        ul = fut_cache.get(d)\n        if ul is None or ul.empty:\n            continue\n        rc = regime_label(d)\n        for t in dt_grid:\n            if t >= len(ul):\n                continue\n            spot = float(ul.iloc[t][\"close\"])\n            y = label_spread_payoff_mem(\n                chain_mem, expiry_mem, name, d, t, hold_min, spot, rc,\n                wing_steps, oi_min, vol_min, price_min, tick_size\n            )\n            if y is not None:\n                label_cache[(d, t)] = y\n                label_ok += 1\n            else:\n                label_fail += 1\n\n    print(f\"{label_ok} labels ({label_fail} skipped) in {time.time()-t0_labels:.0f}s\")\n\n    # ── Walk-forward per ablation ──\n    for abl_idx, drop_groups in enumerate(ablations):\n        abl_key = tuple(drop_groups)\n        abl_label = \"|\".join(drop_groups) if drop_groups else \"baseline\"\n        print(f\"\\n[Ablation {abl_idx+1}/{len(ablations)}] drop={abl_label}\")\n\n        all_candidates = []\n        fold_count = 0\n\n        for start in range(0, len(days) - (train_days + test_days) + 1, test_days):\n            train = days[start:start+train_days]\n            test = days[start+train_days:start+train_days+test_days]\n\n            # ── Training: use spread payoff labels ──\n            X_train, y_train = [], []\n            for d in train:\n                ul = fut_cache.get(d)\n                if ul is None or ul.empty:\n                    continue\n                for t in dt_grid:\n                    if t >= len(ul):\n                        continue\n                    y = label_cache.get((d, t))\n                    if y is None:\n                        continue\n                    ul_upto = ul.iloc[:t+1]\n                    feat = build_features_upto(ul_upto, day=d)\n                    if feat is None:\n                        continue\n                    feat = ablate_feat(feat, drop_groups)\n                    if not feat:\n                        continue\n                    X_train.append(feat)\n                    y_train.append(y)\n\n            if len(X_train) < 200:\n                continue\n\n            model = fit_ridge(X_train, y_train, l2=1.0)\n            fold_count += 1\n\n            # ── Test fold ──\n            for d in test:\n                ul = fut_cache.get(d)\n                if ul is None or ul.empty:\n                    continue\n\n                rc = regime_label(d)\n\n                for t in dt_grid:\n                    t_exit = min(t + hold_min, exit_min)\n                    if t_exit >= len(ul) or t >= len(ul):\n                        continue\n\n                    ul_upto = ul.iloc[:t+1]\n                    feat = build_features_upto(ul_upto, day=d)\n                    if feat is None:\n                        continue\n                    feat = ablate_feat(feat, drop_groups)\n                    if not feat:\n                        continue\n\n                    score = model.predict_score(feat)\n                    if abs(score) < threshold:\n                        continue\n\n                    spot = float(ul.iloc[t][\"close\"])\n\n                    trade = build_spread_trade_mem(\n                        chain_mem, expiry_mem, name, d, t, spot, score, rc,\n                        threshold, wing_steps, oi_min, vol_min, price_min\n                    )\n                    if trade is None:\n                        continue\n\n                    legs, risk_cap, structure = trade\n\n                    entry_closes = {}\n                    exit_closes = {}\n                    valid = True\n                    for leg in legs:\n                        e_bar = contract_at_minute_mem(chain_mem, d, leg.symbol, t)\n                        x_bar = contract_at_minute_mem(chain_mem, d, leg.symbol, t_exit)\n                        if e_bar is None or x_bar is None:\n                            valid = False\n                            break\n                        if x_bar[\"oi\"] < oi_min or x_bar[\"volume\"] < vol_min:\n                            valid = False\n                            break\n                        entry_closes[leg.symbol] = e_bar[\"close\"]\n                        exit_closes[leg.symbol] = x_bar[\"close\"]\n\n                    if not valid:\n                        continue\n\n                    all_candidates.append({\n                        \"day\": d, \"t_entry\": t, \"t_exit\": t_exit,\n                        \"score\": score, \"spot\": spot,\n                        \"regime\": rc,\n                        \"regime_detail\": regime_detail(d),\n                        \"structure\": structure,\n                        \"risk_cap\": risk_cap,\n                        \"legs\": legs,\n                        \"entry_closes\": entry_closes,\n                        \"exit_closes\": exit_closes,\n                    })\n\n            if fold_count % 5 == 0:\n                print(f\"  Fold {fold_count}: {len(all_candidates)} candidates\", flush=True)\n\n        print(f\"  Total: {fold_count} folds, {len(all_candidates)} candidates\")\n\n        # ── Cost sweep in-memory ──\n        for spread_ticks, fees_bps in cost_grid:\n            key = (spread_ticks, fees_bps, abl_key)\n            trade_log = []\n            equity = 1.0\n\n            for c in all_candidates:\n                pnl = structure_pnl(\n                    c[\"legs\"], c[\"entry_closes\"], c[\"exit_closes\"],\n                    spread_ticks=spread_ticks, tick_size=tick_size,\n                    fees_bps=fees_bps\n                )\n                if pnl is None:\n                    continue\n\n                r = pnl[\"net\"] / max(1e-8, c[\"risk_cap\"])\n                equity *= (1.0 + r)\n\n                trade_log.append({\n                    \"day\": c[\"day\"], \"t_entry\": c[\"t_entry\"], \"t_exit\": c[\"t_exit\"],\n                    \"score\": c[\"score\"], \"spot\": c[\"spot\"],\n                    \"spread_ticks\": spread_ticks, \"fees_bps\": fees_bps,\n                    \"drop_groups\": abl_label,\n                    \"regime\": c[\"regime\"],\n                    \"regime_detail\": c[\"regime_detail\"],\n                    \"structure\": c[\"structure\"],\n                    \"risk_cap\": c[\"risk_cap\"],\n                    \"gross\": pnl[\"gross\"], \"fees\": pnl[\"fees\"],\n                    \"net\": pnl[\"net\"], \"r\": r,\n                })\n\n            trades_df = pd.DataFrame(trade_log) if trade_log else pd.DataFrame()\n            results[key] = {\n                \"equity_final\": equity,\n                \"trades\": len(trade_log),\n                \"trades_df\": trades_df,\n                \"folds\": fold_count,\n            }\n\n        ref = results.get((cost_grid[0][0], cost_grid[0][1], abl_key))\n        if ref:\n            print(f\"  -> {ref['trades']} trades, eq={ref['equity_final']:.4f} \"\n                  f\"(ticks={cost_grid[0][0]}, fees={cost_grid[0][1]})\")\n\n    return results\n\n\nprint(\"Walk-forward ready (in-memory, spread payoff labels, SANOS regime gating)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "982e9442",
   "metadata": {},
   "source": "\"\"\"Cell 11: Reporting — cost frontier, ablation stability, regime + structure tables.\"\"\"\n\ndef equity_curve_from_returns(returns):\n    \"\"\"Multiplicative equity curve.\"\"\"\n    r = np.asarray(returns, dtype=float)\n    eq = np.empty(len(r) + 1, dtype=float)\n    eq[0] = 1.0\n    for i in range(len(r)):\n        eq[i + 1] = eq[i] * (1.0 + r[i])\n    return eq\n\n\ndef sharpe_daily_from_trades(trades_df, ann_factor=252.0):\n    \"\"\"Annualized Sharpe from trade returns grouped by day.\"\"\"\n    if trades_df.empty:\n        return 0.0\n    daily = trades_df.groupby(\"day\")[\"r\"].sum()\n    if len(daily) < 2:\n        return 0.0\n    mu = daily.mean()\n    sd = daily.std(ddof=1)\n    if sd == 0:\n        return 0.0\n    return float(mu / sd * np.sqrt(ann_factor))\n\n\ndef cost_frontier_table(results):\n    \"\"\"For each cost scenario (baseline ablation), show equity + Sharpe.\"\"\"\n    rows = []\n    for (spread_ticks, fees_bps, drop_groups), v in results.items():\n        if drop_groups != tuple():\n            continue\n        tdf = v[\"trades_df\"]\n        sharpe = sharpe_daily_from_trades(tdf)\n        wr = float((tdf[\"r\"] > 0).mean()) if not tdf.empty else 0.0\n        rows.append({\n            \"spread_ticks\": spread_ticks, \"fees_bps\": fees_bps,\n            \"equity\": v[\"equity_final\"],\n            \"return_%\": (v[\"equity_final\"] - 1.0) * 100,\n            \"trades\": v[\"trades\"],\n            \"sharpe\": sharpe,\n            \"win_rate_%\": wr * 100,\n        })\n    df = pd.DataFrame(rows).sort_values([\"spread_ticks\", \"fees_bps\"])\n    return df\n\n\ndef ablation_table(results):\n    \"\"\"Compare ablation scenarios at reference cost.\"\"\"\n    ref_cost = None\n    for k in results.keys():\n        ref_cost = (k[0], k[1])\n        break\n    if ref_cost is None:\n        return pd.DataFrame()\n    rows = []\n    for (spread_ticks, fees_bps, drop_groups), v in results.items():\n        if (spread_ticks, fees_bps) != ref_cost:\n            continue\n        tdf = v[\"trades_df\"]\n        sharpe = sharpe_daily_from_trades(tdf)\n        rows.append({\n            \"drop_groups\": \"|\".join(drop_groups) if drop_groups else \"baseline\",\n            \"equity\": v[\"equity_final\"],\n            \"return_%\": (v[\"equity_final\"] - 1.0) * 100,\n            \"trades\": v[\"trades\"],\n            \"sharpe\": sharpe,\n        })\n    df = pd.DataFrame(rows).sort_values(\"sharpe\", ascending=False)\n    return df\n\n\ndef regime_table(trades_df):\n    \"\"\"Per-regime performance breakdown.\"\"\"\n    if trades_df.empty:\n        return pd.DataFrame()\n    g = trades_df.groupby(\"regime\")[\"r\"]\n    out = pd.DataFrame({\n        \"trades\": g.size(),\n        \"mean_r_%\": g.mean() * 100,\n        \"median_r_%\": g.median() * 100,\n        \"win_rate_%\": g.apply(lambda x: float((x > 0).mean()) * 100),\n        \"total_r_%\": g.sum() * 100,\n    }).sort_values(\"mean_r_%\", ascending=False)\n    return out\n\n\ndef structure_table(trades_df):\n    \"\"\"Per-structure (debit vs credit) performance breakdown.\"\"\"\n    if trades_df.empty or \"structure\" not in trades_df.columns:\n        return pd.DataFrame()\n    g = trades_df.groupby(\"structure\")[\"r\"]\n    out = pd.DataFrame({\n        \"trades\": g.size(),\n        \"mean_r_%\": g.mean() * 100,\n        \"median_r_%\": g.median() * 100,\n        \"win_rate_%\": g.apply(lambda x: float((x > 0).mean()) * 100),\n        \"total_r_%\": g.sum() * 100,\n    }).sort_values(\"mean_r_%\", ascending=False)\n    return out\n\n\nprint(\"Reporting functions ready (+ structure breakdown)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0333a81f",
   "metadata": {},
   "source": "\"\"\"Cell 12: Execute full evaluation.\"\"\"\n\nprint(f\"Starting walk-forward evaluation: {NAME}\")\nprint(f\"  Days: {len(days)}, Train: {TRAIN_DAYS}d, Test: {TEST_DAYS}d\")\nprint(f\"  Cost grid: {len(COST_GRID)}, Ablations: {len(ABLATIONS)}\")\nprint(f\"  Total scenarios: {len(COST_GRID) * len(ABLATIONS)}\")\nprint()\n\nt_start = time.time()\n\nresults = walkforward_intraday(\n    con, chain_mem=chain_mem, expiry_mem=expiry_mem,\n    name=NAME, days=days,\n    train_days=TRAIN_DAYS, test_days=TEST_DAYS,\n    step=DECISION_STEP, entry_min=ENTRY_MIN, exit_min=EXIT_MIN, hold_min=HOLD_MIN,\n    threshold=SCORE_THRESHOLD, wing_steps=WING_STEPS,\n    oi_min=OI_MIN, vol_min=VOL_MIN, price_min=PRICE_MIN,\n    tick_size=TICK_SIZE,\n    cost_grid=COST_GRID, ablations=ABLATIONS,\n)\n\nelapsed = time.time() - t_start\nprint(f\"\\nDone in {elapsed:.1f}s\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cb94a05b",
   "metadata": {},
   "source": "\"\"\"Cell 13: Results — cost frontier, ablation, regime, structure.\"\"\"\n\n# Cost frontier (baseline features, all cost scenarios)\nprint(\"=\" * 60)\nprint(\"COST FRONTIER (baseline features)\")\nprint(\"=\" * 60)\ncf = cost_frontier_table(results)\nprint(cf.to_string(index=False))\n\n# Ablation stability\nprint(f\"\\n{'=' * 60}\")\nprint(\"FEATURE ABLATION STABILITY\")\nprint(\"=\" * 60)\nat = ablation_table(results)\nprint(at.to_string(index=False))\n\n# Regime breakdown (baseline, reference cost)\nref_key = None\nfor k in results.keys():\n    if k[2] == tuple():\n        ref_key = k\n        break\n\nif ref_key and not results[ref_key][\"trades_df\"].empty:\n    tdf = results[ref_key][\"trades_df\"]\n\n    print(f\"\\n{'=' * 60}\")\n    print(f\"REGIME BREAKDOWN (ticks={ref_key[0]}, fees={ref_key[1]})\")\n    print(\"=\" * 60)\n    rt = regime_table(tdf)\n    print(rt.to_string())\n\n    print(f\"\\n{'=' * 60}\")\n    print(f\"STRUCTURE BREAKDOWN (debit vs credit)\")\n    print(\"=\" * 60)\n    st = structure_table(tdf)\n    print(st.to_string())\nelse:\n    print(\"\\nNo trades in reference scenario — cannot compute breakdowns.\")\n\n# Overall verdict\nprint(f\"\\n{'=' * 60}\")\nprint(\"VERDICT\")\nprint(\"=\" * 60)\nif not cf.empty:\n    profitable = cf[cf[\"return_%\"] > 0]\n    total = len(cf)\n    print(f\"Profitable in {len(profitable)}/{total} cost scenarios\")\n    if len(profitable) > 0:\n        worst_profitable = profitable.sort_values(\"return_%\").iloc[0]\n        print(f\"  Worst profitable: ticks={int(worst_profitable['spread_ticks'])}, \"\n              f\"fees={worst_profitable['fees_bps']:.0f}bps -> {worst_profitable['return_%']:+.2f}%\")\n    if len(profitable) == 0:\n        print(\"  Strategy is NOT profitable under any tested cost scenario.\")\n    elif len(profitable) < total // 2:\n        print(\"  Marginal: profitable only under optimistic cost assumptions.\")\n    else:\n        print(\"  Robust: profitable across majority of cost scenarios.\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5fd7ebff",
   "metadata": {},
   "source": [
    "\"\"\"Cell 14: Equity curve visualization.\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot equity curves for baseline ablation across cost scenarios\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "ax = axes[0]\n",
    "for (spread_ticks, fees_bps, drop_groups), v in results.items():\n",
    "    if drop_groups != tuple():\n",
    "        continue\n",
    "    tdf = v[\"trades_df\"]\n",
    "    if tdf.empty:\n",
    "        continue\n",
    "    eq = equity_curve_from_returns(tdf[\"r\"].values)\n",
    "    label = f\"ticks={spread_ticks}, fees={fees_bps:.0f}bps ({v['trades']} trades)\"\n",
    "    ax.plot(eq, linewidth=0.8, label=label)\n",
    "\n",
    "ax.legend(fontsize=7, loc=\"upper left\")\n",
    "ax.set_ylabel(\"Equity\")\n",
    "ax.set_title(f\"{NAME} — Intraday Options: Cost Sensitivity\")\n",
    "ax.axhline(1.0, color=\"black\", linewidth=0.5, linestyle=\"--\")\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Ablation comparison at reference cost\n",
    "ax = axes[1]\n",
    "ref_cost = None\n",
    "for k in results.keys():\n",
    "    ref_cost = (k[0], k[1])\n",
    "    break\n",
    "\n",
    "if ref_cost:\n",
    "    for (spread_ticks, fees_bps, drop_groups), v in results.items():\n",
    "        if (spread_ticks, fees_bps) != ref_cost:\n",
    "            continue\n",
    "        tdf = v[\"trades_df\"]\n",
    "        if tdf.empty:\n",
    "            continue\n",
    "        eq = equity_curve_from_returns(tdf[\"r\"].values)\n",
    "        label = \"|\".join(drop_groups) if drop_groups else \"baseline\"\n",
    "        ax.plot(eq, linewidth=0.8, label=f\"drop:{label} ({v['trades']} trades)\")\n",
    "\n",
    "    ax.legend(fontsize=7, loc=\"upper left\")\n",
    "    ax.set_ylabel(\"Equity\")\n",
    "    ax.set_title(f\"{NAME} — Feature Ablation (ticks={ref_cost[0]}, fees={ref_cost[1]})\")\n",
    "    ax.axhline(1.0, color=\"black\", linewidth=0.5, linestyle=\"--\")\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}