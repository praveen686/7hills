{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Symbol Arbitrage Research Skeleton\n",
    "\n",
    "This notebook provides a flexible framework for arbitrage research using VectorBT.\n",
    "\n",
    "**Key Features:**\n",
    "- Schema-agnostic CSV/JSONL loading with automatic column discovery\n",
    "- Multi-symbol time alignment utilities\n",
    "- Spread calculation helpers for various arbitrage strategies\n",
    "- VectorBT portfolio integration points\n",
    "\n",
    "**Data Sources:**\n",
    "- `depth.jsonl` - Order book snapshots/diffs\n",
    "- `trades.jsonl` - Trade events\n",
    "- Any CSV with timestamp and price columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Callable\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "# VectorBT imports (install with: pip install vectorbt)\n",
    "try:\n",
    "    import vectorbt as vbt\n",
    "    VBT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    warnings.warn(\"VectorBT not installed. Portfolio features disabled. Install with: pip install vectorbt\")\n",
    "    VBT_AVAILABLE = False\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Configuration\n",
    "\n",
    "Define your data paths and trading parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA CONFIGURATION ===\n",
    "# Point to your session data directory\n",
    "DATA_ROOT = Path(\"../data/sessions\")  # Adjust as needed\n",
    "SESSION_NAME = \"profile1_2h_20260122_2138\"  # Adjust to your session\n",
    "\n",
    "# Symbols for arbitrage analysis\n",
    "SYMBOLS = [\"BTCUSDT\", \"ETHUSDT\", \"ETHBTC\"]  # Example: triangular arb\n",
    "\n",
    "# === TRADING PARAMETERS ===\n",
    "TRADING_FEES = {\n",
    "    \"maker\": 0.001,  # 0.1% maker fee (adjust per exchange)\n",
    "    \"taker\": 0.001,  # 0.1% taker fee\n",
    "}\n",
    "\n",
    "# Time alignment parameters\n",
    "RESAMPLE_FREQ = \"100ms\"  # Resample frequency for alignment\n",
    "FFILL_LIMIT = 10  # Max forward-fill periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Flexible Data Loading\n",
    "\n",
    "Schema-agnostic loaders that discover columns dynamically from CSV or JSONL files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleDataLoader:\n",
    "    \"\"\"\n",
    "    Schema-agnostic data loader with automatic column discovery.\n",
    "    Supports CSV and JSONL formats.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Common timestamp column names to try\n",
    "    TIMESTAMP_CANDIDATES = ['ts', 'timestamp', 'time', 'datetime', 'date', 't', 'event_time']\n",
    "    # Common price column names to try\n",
    "    PRICE_CANDIDATES = ['price', 'close', 'last', 'mid', 'mark_price', 'ltp']\n",
    "    \n",
    "    def __init__(self, path: Path):\n",
    "        self.path = Path(path)\n",
    "        self.df: Optional[pd.DataFrame] = None\n",
    "        self.schema: Dict = {}\n",
    "    \n",
    "    def load(self, **read_kwargs) -> pd.DataFrame:\n",
    "        \"\"\"Load data from file, auto-detecting format.\"\"\"\n",
    "        suffix = self.path.suffix.lower()\n",
    "        \n",
    "        if suffix == '.jsonl':\n",
    "            self.df = self._load_jsonl(**read_kwargs)\n",
    "        elif suffix == '.csv':\n",
    "            self.df = pd.read_csv(self.path, **read_kwargs)\n",
    "        elif suffix == '.parquet':\n",
    "            self.df = pd.read_parquet(self.path, **read_kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {suffix}\")\n",
    "        \n",
    "        self._discover_schema()\n",
    "        return self.df\n",
    "    \n",
    "    def _load_jsonl(self, nrows: Optional[int] = None, **kwargs) -> pd.DataFrame:\n",
    "        \"\"\"Load JSONL file line by line.\"\"\"\n",
    "        records = []\n",
    "        with open(self.path, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if nrows and i >= nrows:\n",
    "                    break\n",
    "                records.append(json.loads(line.strip()))\n",
    "        return pd.DataFrame(records)\n",
    "    \n",
    "    def _discover_schema(self):\n",
    "        \"\"\"Automatically discover column types and roles.\"\"\"\n",
    "        if self.df is None:\n",
    "            return\n",
    "        \n",
    "        self.schema = {\n",
    "            'columns': list(self.df.columns),\n",
    "            'dtypes': self.df.dtypes.to_dict(),\n",
    "            'shape': self.df.shape,\n",
    "            'timestamp_col': self._find_timestamp_col(),\n",
    "            'price_col': self._find_price_col(),\n",
    "        }\n",
    "    \n",
    "    def _find_timestamp_col(self) -> Optional[str]:\n",
    "        \"\"\"Find the most likely timestamp column.\"\"\"\n",
    "        for candidate in self.TIMESTAMP_CANDIDATES:\n",
    "            if candidate in self.df.columns:\n",
    "                return candidate\n",
    "        # Try to find datetime-like columns\n",
    "        for col in self.df.columns:\n",
    "            if self.df[col].dtype == 'datetime64[ns]':\n",
    "                return col\n",
    "            # Try parsing first non-null value\n",
    "            sample = self.df[col].dropna().iloc[0] if len(self.df[col].dropna()) > 0 else None\n",
    "            if isinstance(sample, str) and ('T' in sample or '-' in sample):\n",
    "                try:\n",
    "                    pd.to_datetime(sample)\n",
    "                    return col\n",
    "                except:\n",
    "                    pass\n",
    "        return None\n",
    "    \n",
    "    def _find_price_col(self) -> Optional[str]:\n",
    "        \"\"\"Find the most likely price column.\"\"\"\n",
    "        for candidate in self.PRICE_CANDIDATES:\n",
    "            if candidate in self.df.columns:\n",
    "                return candidate\n",
    "        return None\n",
    "    \n",
    "    def describe_schema(self):\n",
    "        \"\"\"Print discovered schema information.\"\"\"\n",
    "        print(f\"File: {self.path.name}\")\n",
    "        print(f\"Shape: {self.schema.get('shape')}\")\n",
    "        print(f\"Detected timestamp column: {self.schema.get('timestamp_col')}\")\n",
    "        print(f\"Detected price column: {self.schema.get('price_col')}\")\n",
    "        print(f\"\\nColumns: {self.schema.get('columns')}\")\n",
    "        print(f\"\\nSample data:\")\n",
    "        display(self.df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_symbol_data(\n",
    "    session_path: Path,\n",
    "    symbol: str,\n",
    "    data_type: str = \"trades\",  # \"trades\" or \"depth\"\n",
    "    nrows: Optional[int] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data for a specific symbol from session directory.\n",
    "    \n",
    "    Args:\n",
    "        session_path: Path to session directory\n",
    "        symbol: Trading symbol (e.g., \"BTCUSDT\")\n",
    "        data_type: \"trades\" or \"depth\"\n",
    "        nrows: Limit number of rows (for testing)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with parsed timestamp index\n",
    "    \"\"\"\n",
    "    file_path = session_path / symbol / f\"{data_type}.jsonl\"\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
    "    \n",
    "    loader = FlexibleDataLoader(file_path)\n",
    "    df = loader.load(nrows=nrows)\n",
    "    \n",
    "    # Parse timestamp if found\n",
    "    ts_col = loader.schema.get('timestamp_col')\n",
    "    if ts_col:\n",
    "        df[ts_col] = pd.to_datetime(df[ts_col])\n",
    "        df = df.set_index(ts_col).sort_index()\n",
    "    \n",
    "    # Add symbol column for multi-symbol processing\n",
    "    df['symbol'] = symbol\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXAMPLE: Load and inspect data ===\n",
    "# Uncomment to test with your data\n",
    "\n",
    "# session_path = DATA_ROOT / SESSION_NAME\n",
    "# btc_trades = load_symbol_data(session_path, \"BTCUSDT\", \"trades\", nrows=1000)\n",
    "# print(f\"Loaded {len(btc_trades)} rows\")\n",
    "# display(btc_trades.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Multi-Symbol Time Alignment\n",
    "\n",
    "Utilities for synchronizing data across multiple symbols with different timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSymbolAligner:\n",
    "    \"\"\"\n",
    "    Align multiple symbol DataFrames to a common time grid.\n",
    "    Essential for arbitrage calculations requiring synchronized prices.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        resample_freq: str = \"100ms\",\n",
    "        ffill_limit: int = 10,\n",
    "        agg_method: str = \"last\"  # How to aggregate within each bin\n",
    "    ):\n",
    "        self.resample_freq = resample_freq\n",
    "        self.ffill_limit = ffill_limit\n",
    "        self.agg_method = agg_method\n",
    "        self.aligned_data: Dict[str, pd.DataFrame] = {}\n",
    "    \n",
    "    def align(\n",
    "        self,\n",
    "        data_dict: Dict[str, pd.DataFrame],\n",
    "        price_col: str = \"price\",\n",
    "        price_exponent_col: Optional[str] = \"price_exponent\"\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Align multiple symbols to common time grid.\n",
    "        \n",
    "        Args:\n",
    "            data_dict: Dict of {symbol: DataFrame} with datetime index\n",
    "            price_col: Column containing price data\n",
    "            price_exponent_col: Optional column with price exponent for fixed-point conversion\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with columns for each symbol's price, aligned in time\n",
    "        \"\"\"\n",
    "        aligned_series = {}\n",
    "        \n",
    "        for symbol, df in data_dict.items():\n",
    "            if price_col not in df.columns:\n",
    "                raise ValueError(f\"Price column '{price_col}' not found in {symbol} data\")\n",
    "            \n",
    "            # Handle fixed-point prices if exponent column exists\n",
    "            if price_exponent_col and price_exponent_col in df.columns:\n",
    "                prices = df[price_col] * (10 ** df[price_exponent_col].iloc[0])\n",
    "            else:\n",
    "                prices = df[price_col]\n",
    "            \n",
    "            # Resample and aggregate\n",
    "            resampled = prices.resample(self.resample_freq).agg(self.agg_method)\n",
    "            aligned_series[symbol] = resampled\n",
    "        \n",
    "        # Combine into single DataFrame\n",
    "        aligned_df = pd.DataFrame(aligned_series)\n",
    "        \n",
    "        # Forward fill with limit\n",
    "        aligned_df = aligned_df.ffill(limit=self.ffill_limit)\n",
    "        \n",
    "        # Drop rows where any symbol is NaN (no valid data)\n",
    "        aligned_df = aligned_df.dropna()\n",
    "        \n",
    "        self.aligned_data = aligned_df\n",
    "        return aligned_df\n",
    "    \n",
    "    def get_alignment_stats(self) -> Dict:\n",
    "        \"\"\"Return statistics about the alignment quality.\"\"\"\n",
    "        if self.aligned_data is None or len(self.aligned_data) == 0:\n",
    "            return {}\n",
    "        \n",
    "        return {\n",
    "            'total_rows': len(self.aligned_data),\n",
    "            'time_range': (self.aligned_data.index.min(), self.aligned_data.index.max()),\n",
    "            'symbols': list(self.aligned_data.columns),\n",
    "            'null_counts': self.aligned_data.isnull().sum().to_dict(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EXAMPLE: Align multiple symbols ===\n",
    "# Uncomment to test with your data\n",
    "\n",
    "# session_path = DATA_ROOT / SESSION_NAME\n",
    "# data_dict = {}\n",
    "# for symbol in SYMBOLS:\n",
    "#     data_dict[symbol] = load_symbol_data(session_path, symbol, \"trades\", nrows=10000)\n",
    "#\n",
    "# aligner = MultiSymbolAligner(resample_freq=RESAMPLE_FREQ)\n",
    "# aligned_prices = aligner.align(data_dict)\n",
    "# print(f\"Aligned data shape: {aligned_prices.shape}\")\n",
    "# display(aligned_prices.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Spread Calculation Utilities\n",
    "\n",
    "Helper functions for computing various arbitrage spreads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpreadCalculator:\n",
    "    \"\"\"\n",
    "    Calculate various spread types for arbitrage analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def simple_spread(\n",
    "        prices_a: pd.Series,\n",
    "        prices_b: pd.Series,\n",
    "        spread_type: str = \"ratio\"  # \"ratio\", \"diff\", \"log_diff\"\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Calculate simple two-asset spread.\n",
    "        \n",
    "        Args:\n",
    "            prices_a: First asset prices\n",
    "            prices_b: Second asset prices\n",
    "            spread_type: Type of spread calculation\n",
    "        \n",
    "        Returns:\n",
    "            Spread series\n",
    "        \"\"\"\n",
    "        if spread_type == \"ratio\":\n",
    "            return prices_a / prices_b\n",
    "        elif spread_type == \"diff\":\n",
    "            return prices_a - prices_b\n",
    "        elif spread_type == \"log_diff\":\n",
    "            return np.log(prices_a) - np.log(prices_b)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown spread type: {spread_type}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def z_score(\n",
    "        spread: pd.Series,\n",
    "        lookback: int = 100,\n",
    "        min_periods: int = 20\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Calculate rolling z-score of spread for mean reversion signals.\n",
    "        \n",
    "        Args:\n",
    "            spread: Spread series\n",
    "            lookback: Rolling window size\n",
    "            min_periods: Minimum periods for valid calculation\n",
    "        \n",
    "        Returns:\n",
    "            Z-score series\n",
    "        \"\"\"\n",
    "        rolling_mean = spread.rolling(window=lookback, min_periods=min_periods).mean()\n",
    "        rolling_std = spread.rolling(window=lookback, min_periods=min_periods).std()\n",
    "        return (spread - rolling_mean) / rolling_std\n",
    "    \n",
    "    @staticmethod\n",
    "    def fee_adjusted_spread(\n",
    "        spread: pd.Series,\n",
    "        fee_rate: float = 0.001,  # Total round-trip fees\n",
    "        num_legs: int = 2  # Number of trades in the arb\n",
    "    ) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Adjust spread for trading fees.\n",
    "        \n",
    "        For arbitrage to be profitable, spread must exceed fees.\n",
    "        \n",
    "        Args:\n",
    "            spread: Raw spread series (as ratio, e.g., 1.001 = 0.1% spread)\n",
    "            fee_rate: Fee rate per trade\n",
    "            num_legs: Number of trades required\n",
    "        \n",
    "        Returns:\n",
    "            Fee-adjusted spread (negative = unprofitable)\n",
    "        \"\"\"\n",
    "        total_fees = fee_rate * num_legs\n",
    "        # Convert ratio spread to percentage, subtract fees\n",
    "        spread_pct = (spread - 1) * 100  # Convert to percentage\n",
    "        return spread_pct - (total_fees * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Triangular Arbitrage Spread Calculation [PLACEHOLDER]\n",
    "\n",
    "Calculate triangular arbitrage opportunities across three currency pairs.\n",
    "\n",
    "**Example:** BTC/USDT, ETH/USDT, ETH/BTC\n",
    "- Buy ETH with USDT\n",
    "- Sell ETH for BTC\n",
    "- Sell BTC for USDT\n",
    "- If final USDT > initial USDT (minus fees), arbitrage exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_triangular_spread(\n",
    "    aligned_prices: pd.DataFrame,\n",
    "    base: str = \"USDT\",  # Base currency\n",
    "    leg1: str = \"BTCUSDT\",  # First leg symbol\n",
    "    leg2: str = \"ETHUSDT\",  # Second leg symbol  \n",
    "    leg3: str = \"ETHBTC\",   # Cross pair symbol\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    [PLACEHOLDER] Calculate triangular arbitrage spread.\n",
    "    \n",
    "    This function calculates the implied vs actual cross rate.\n",
    "    \n",
    "    For BTC/USDT, ETH/USDT, ETH/BTC:\n",
    "    - Implied ETH/BTC = ETH/USDT / BTC/USDT\n",
    "    - Spread = Actual ETH/BTC / Implied ETH/BTC\n",
    "    \n",
    "    Args:\n",
    "        aligned_prices: DataFrame with aligned prices for all symbols\n",
    "        base: Base currency for the triangle\n",
    "        leg1, leg2, leg3: Symbol names for the three legs\n",
    "    \n",
    "    Returns:\n",
    "        Series with triangular spread (>1 = arb opportunity direction A, <1 = direction B)\n",
    "    \"\"\"\n",
    "    # TODO: Implement triangular arbitrage spread calculation\n",
    "    # Example structure:\n",
    "    #\n",
    "    # btc_usdt = aligned_prices[leg1]\n",
    "    # eth_usdt = aligned_prices[leg2]\n",
    "    # eth_btc_actual = aligned_prices[leg3]\n",
    "    #\n",
    "    # eth_btc_implied = eth_usdt / btc_usdt\n",
    "    # triangular_spread = eth_btc_actual / eth_btc_implied\n",
    "    #\n",
    "    # return triangular_spread\n",
    "    \n",
    "    raise NotImplementedError(\"Implement triangular arbitrage spread calculation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TRIANGULAR ARB ANALYSIS PLACEHOLDER ===\n",
    "# Uncomment and complete after implementing calculate_triangular_spread\n",
    "\n",
    "# tri_spread = calculate_triangular_spread(aligned_prices)\n",
    "# print(f\"Triangular spread stats:\")\n",
    "# print(f\"  Mean: {tri_spread.mean():.6f}\")\n",
    "# print(f\"  Std:  {tri_spread.std():.6f}\")\n",
    "# print(f\"  Min:  {tri_spread.min():.6f}\")\n",
    "# print(f\"  Max:  {tri_spread.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Statistical Arbitrage Z-Score Calculation [PLACEHOLDER]\n",
    "\n",
    "Calculate z-scores for pairs trading / statistical arbitrage strategies.\n",
    "\n",
    "**Concept:** Two correlated assets should maintain a stable price ratio. When the ratio deviates significantly (high z-score), we expect mean reversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stat_arb_zscore(\n",
    "    aligned_prices: pd.DataFrame,\n",
    "    symbol_a: str,\n",
    "    symbol_b: str,\n",
    "    lookback: int = 500,\n",
    "    spread_type: str = \"log_diff\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    [PLACEHOLDER] Calculate statistical arbitrage z-score.\n",
    "    \n",
    "    Args:\n",
    "        aligned_prices: DataFrame with aligned prices\n",
    "        symbol_a: First symbol\n",
    "        symbol_b: Second symbol\n",
    "        lookback: Rolling window for z-score calculation\n",
    "        spread_type: Type of spread calculation\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: ['spread', 'zscore', 'rolling_mean', 'rolling_std']\n",
    "    \"\"\"\n",
    "    # TODO: Implement statistical arbitrage z-score calculation\n",
    "    # Example structure:\n",
    "    #\n",
    "    # calc = SpreadCalculator()\n",
    "    # spread = calc.simple_spread(\n",
    "    #     aligned_prices[symbol_a],\n",
    "    #     aligned_prices[symbol_b],\n",
    "    #     spread_type=spread_type\n",
    "    # )\n",
    "    # zscore = calc.z_score(spread, lookback=lookback)\n",
    "    #\n",
    "    # return pd.DataFrame({\n",
    "    #     'spread': spread,\n",
    "    #     'zscore': zscore,\n",
    "    #     'rolling_mean': spread.rolling(lookback).mean(),\n",
    "    #     'rolling_std': spread.rolling(lookback).std(),\n",
    "    # })\n",
    "    \n",
    "    raise NotImplementedError(\"Implement statistical arbitrage z-score calculation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === STAT ARB ANALYSIS PLACEHOLDER ===\n",
    "# Uncomment and complete after implementing calculate_stat_arb_zscore\n",
    "\n",
    "# stat_arb_df = calculate_stat_arb_zscore(aligned_prices, \"BTCUSDT\", \"ETHUSDT\")\n",
    "# print(f\"Z-score distribution:\")\n",
    "# print(stat_arb_df['zscore'].describe())\n",
    "#\n",
    "# # Count extreme z-scores (potential signals)\n",
    "# extreme_long = (stat_arb_df['zscore'] < -2).sum()\n",
    "# extreme_short = (stat_arb_df['zscore'] > 2).sum()\n",
    "# print(f\"\\nExtreme z-scores (|z| > 2): Long signals: {extreme_long}, Short signals: {extreme_short}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Fee-Adjusted Return Calculation [PLACEHOLDER]\n",
    "\n",
    "Calculate net returns after accounting for trading fees.\n",
    "\n",
    "**Important:** Arbitrage opportunities often appear profitable before fees but become unprofitable after accounting for:\n",
    "- Maker/taker fees\n",
    "- Slippage\n",
    "- Network/gas fees (for DeFi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fee_adjusted_returns(\n",
    "    spread: pd.Series,\n",
    "    entry_threshold: float = 0.002,  # 0.2% spread to enter\n",
    "    exit_threshold: float = 0.0,     # Exit when spread returns to 0\n",
    "    fee_per_leg: float = 0.001,      # 0.1% per trade\n",
    "    num_legs: int = 2,               # Number of trades per arb\n",
    "    slippage_bps: float = 1.0,       # 1 bps slippage per trade\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    [PLACEHOLDER] Calculate fee-adjusted arbitrage returns.\n",
    "    \n",
    "    Args:\n",
    "        spread: Spread series (as ratio where 1.0 = no spread)\n",
    "        entry_threshold: Minimum spread to enter position\n",
    "        exit_threshold: Spread level to exit position\n",
    "        fee_per_leg: Fee rate per trade leg\n",
    "        num_legs: Number of trade legs in the arbitrage\n",
    "        slippage_bps: Expected slippage in basis points per trade\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: ['gross_return', 'fees', 'slippage', 'net_return', 'profitable']\n",
    "    \"\"\"\n",
    "    # TODO: Implement fee-adjusted return calculation\n",
    "    # Example structure:\n",
    "    #\n",
    "    # gross_return = (spread - 1) * 100  # Convert to percentage\n",
    "    #\n",
    "    # total_fees = fee_per_leg * num_legs * 100  # As percentage\n",
    "    # total_slippage = (slippage_bps / 100) * num_legs  # As percentage\n",
    "    #\n",
    "    # net_return = gross_return - total_fees - total_slippage\n",
    "    # profitable = net_return > 0\n",
    "    #\n",
    "    # return pd.DataFrame({\n",
    "    #     'gross_return': gross_return,\n",
    "    #     'fees': total_fees,\n",
    "    #     'slippage': total_slippage,\n",
    "    #     'net_return': net_return,\n",
    "    #     'profitable': profitable,\n",
    "    # })\n",
    "    \n",
    "    raise NotImplementedError(\"Implement fee-adjusted return calculation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FEE-ADJUSTED RETURNS PLACEHOLDER ===\n",
    "# Uncomment and complete after implementing calculate_fee_adjusted_returns\n",
    "\n",
    "# returns_df = calculate_fee_adjusted_returns(tri_spread)\n",
    "# print(f\"Return analysis:\")\n",
    "# print(f\"  Gross return mean: {returns_df['gross_return'].mean():.4f}%\")\n",
    "# print(f\"  Net return mean:   {returns_df['net_return'].mean():.4f}%\")\n",
    "# print(f\"  Profitable periods: {returns_df['profitable'].sum()} / {len(returns_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Basic Visualization Scaffolding\n",
    "\n",
    "Visualization helpers for arbitrage analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArbVisualizer:\n",
    "    \"\"\"\n",
    "    Visualization utilities for arbitrage research.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_aligned_prices(\n",
    "        aligned_prices: pd.DataFrame,\n",
    "        normalize: bool = True,\n",
    "        figsize: tuple = (14, 6)\n",
    "    ):\n",
    "        \"\"\"Plot aligned prices for multiple symbols.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        data = aligned_prices.copy()\n",
    "        if normalize:\n",
    "            data = data / data.iloc[0] * 100  # Normalize to 100\n",
    "            ax.set_ylabel('Normalized Price (start=100)')\n",
    "        else:\n",
    "            ax.set_ylabel('Price')\n",
    "        \n",
    "        for col in data.columns:\n",
    "            ax.plot(data.index, data[col], label=col, alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_title('Aligned Prices')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig, ax\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_spread_zscore(\n",
    "        spread: pd.Series,\n",
    "        zscore: pd.Series,\n",
    "        entry_threshold: float = 2.0,\n",
    "        figsize: tuple = (14, 8)\n",
    "    ):\n",
    "        \"\"\"Plot spread and z-score with entry threshold bands.\"\"\"\n",
    "        fig, axes = plt.subplots(2, 1, figsize=figsize, sharex=True)\n",
    "        \n",
    "        # Spread plot\n",
    "        axes[0].plot(spread.index, spread, label='Spread', color='blue', alpha=0.8)\n",
    "        axes[0].axhline(y=spread.mean(), color='red', linestyle='--', label='Mean')\n",
    "        axes[0].set_ylabel('Spread')\n",
    "        axes[0].set_title('Spread Time Series')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Z-score plot with bands\n",
    "        axes[1].plot(zscore.index, zscore, label='Z-Score', color='green', alpha=0.8)\n",
    "        axes[1].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        axes[1].axhline(y=entry_threshold, color='red', linestyle='--', label=f'+{entry_threshold} threshold')\n",
    "        axes[1].axhline(y=-entry_threshold, color='red', linestyle='--', label=f'-{entry_threshold} threshold')\n",
    "        axes[1].fill_between(zscore.index, -entry_threshold, entry_threshold, alpha=0.1, color='gray')\n",
    "        axes[1].set_ylabel('Z-Score')\n",
    "        axes[1].set_xlabel('Time')\n",
    "        axes[1].set_title('Z-Score with Entry Thresholds')\n",
    "        axes[1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig, axes\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_spread_distribution(\n",
    "        spread: pd.Series,\n",
    "        bins: int = 100,\n",
    "        figsize: tuple = (10, 6)\n",
    "    ):\n",
    "        \"\"\"Plot spread distribution histogram.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        ax.hist(spread.dropna(), bins=bins, edgecolor='black', alpha=0.7)\n",
    "        ax.axvline(x=spread.mean(), color='red', linestyle='--', label=f'Mean: {spread.mean():.6f}')\n",
    "        ax.axvline(x=spread.median(), color='green', linestyle='--', label=f'Median: {spread.median():.6f}')\n",
    "        \n",
    "        ax.set_xlabel('Spread Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title('Spread Distribution')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VISUALIZATION EXAMPLE ===\n",
    "# Uncomment to test with your data\n",
    "\n",
    "# viz = ArbVisualizer()\n",
    "# fig, ax = viz.plot_aligned_prices(aligned_prices, normalize=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. VectorBT Portfolio Integration\n",
    "\n",
    "Integration points for VectorBT backtesting and portfolio management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBTArbPortfolio:\n",
    "    \"\"\"\n",
    "    VectorBT portfolio wrapper for arbitrage backtesting.\n",
    "    \n",
    "    This class provides integration points for running arbitrage strategies\n",
    "    through VectorBT's portfolio simulation engine.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, prices: pd.DataFrame, fees: float = 0.001):\n",
    "        \"\"\"\n",
    "        Initialize VBT portfolio wrapper.\n",
    "        \n",
    "        Args:\n",
    "            prices: DataFrame with price columns for each symbol\n",
    "            fees: Trading fee rate (applies to both entry and exit)\n",
    "        \"\"\"\n",
    "        if not VBT_AVAILABLE:\n",
    "            raise ImportError(\"VectorBT not installed. Run: pip install vectorbt\")\n",
    "        \n",
    "        self.prices = prices\n",
    "        self.fees = fees\n",
    "        self.portfolio = None\n",
    "    \n",
    "    def generate_signals_from_zscore(\n",
    "        self,\n",
    "        zscore: pd.Series,\n",
    "        entry_threshold: float = 2.0,\n",
    "        exit_threshold: float = 0.5,\n",
    "    ) -> tuple:\n",
    "        \"\"\"\n",
    "        Generate entry/exit signals from z-score series.\n",
    "        \n",
    "        Args:\n",
    "            zscore: Z-score series\n",
    "            entry_threshold: Z-score level to enter position\n",
    "            exit_threshold: Z-score level to exit position\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (entries, exits) boolean Series\n",
    "        \"\"\"\n",
    "        # Long spread when z-score is very negative (expect reversion up)\n",
    "        long_entries = zscore < -entry_threshold\n",
    "        long_exits = zscore > -exit_threshold\n",
    "        \n",
    "        # Short spread when z-score is very positive (expect reversion down)\n",
    "        short_entries = zscore > entry_threshold\n",
    "        short_exits = zscore < exit_threshold\n",
    "        \n",
    "        return {\n",
    "            'long_entries': long_entries,\n",
    "            'long_exits': long_exits,\n",
    "            'short_entries': short_entries,\n",
    "            'short_exits': short_exits,\n",
    "        }\n",
    "    \n",
    "    def run_spread_backtest(\n",
    "        self,\n",
    "        spread: pd.Series,\n",
    "        entries: pd.Series,\n",
    "        exits: pd.Series,\n",
    "        init_cash: float = 100000,\n",
    "        size: float = 1.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Run backtest on spread using VectorBT.\n",
    "        \n",
    "        Note: This is a simplified example. For real arbitrage,\n",
    "        you'd need to track positions in multiple assets.\n",
    "        \n",
    "        Args:\n",
    "            spread: Spread series to trade\n",
    "            entries: Boolean entry signals\n",
    "            exits: Boolean exit signals\n",
    "            init_cash: Initial cash\n",
    "            size: Position size\n",
    "        \n",
    "        Returns:\n",
    "            VectorBT Portfolio object\n",
    "        \"\"\"\n",
    "        self.portfolio = vbt.Portfolio.from_signals(\n",
    "            close=spread,\n",
    "            entries=entries,\n",
    "            exits=exits,\n",
    "            init_cash=init_cash,\n",
    "            size=size,\n",
    "            fees=self.fees,\n",
    "            freq='1T',  # Adjust based on your data frequency\n",
    "        )\n",
    "        return self.portfolio\n",
    "    \n",
    "    def get_stats(self) -> pd.Series:\n",
    "        \"\"\"Get portfolio statistics.\"\"\"\n",
    "        if self.portfolio is None:\n",
    "            raise ValueError(\"Run backtest first\")\n",
    "        return self.portfolio.stats()\n",
    "    \n",
    "    def plot_equity(self):\n",
    "        \"\"\"Plot equity curve.\"\"\"\n",
    "        if self.portfolio is None:\n",
    "            raise ValueError(\"Run backtest first\")\n",
    "        return self.portfolio.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VECTORBT BACKTEST EXAMPLE ===\n",
    "# Uncomment to test with your data\n",
    "\n",
    "# if VBT_AVAILABLE:\n",
    "#     # Calculate spread and z-score\n",
    "#     calc = SpreadCalculator()\n",
    "#     spread = calc.simple_spread(aligned_prices['BTCUSDT'], aligned_prices['ETHUSDT'], 'log_diff')\n",
    "#     zscore = calc.z_score(spread, lookback=500)\n",
    "#     \n",
    "#     # Initialize portfolio\n",
    "#     vbt_portfolio = VBTArbPortfolio(aligned_prices, fees=0.001)\n",
    "#     \n",
    "#     # Generate signals\n",
    "#     signals = vbt_portfolio.generate_signals_from_zscore(zscore, entry_threshold=2.0)\n",
    "#     \n",
    "#     # Run backtest (using long signals only for simplicity)\n",
    "#     portfolio = vbt_portfolio.run_spread_backtest(\n",
    "#         spread=spread,\n",
    "#         entries=signals['long_entries'],\n",
    "#         exits=signals['long_exits'],\n",
    "#     )\n",
    "#     \n",
    "#     # Display stats\n",
    "#     print(vbt_portfolio.get_stats())\n",
    "#     vbt_portfolio.plot_equity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Utility Functions\n",
    "\n",
    "Additional helper functions for common operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_session_symbols(session_path: Path) -> List[str]:\n",
    "    \"\"\"\n",
    "    Discover all available symbols in a session directory.\n",
    "    \n",
    "    Args:\n",
    "        session_path: Path to session directory\n",
    "    \n",
    "    Returns:\n",
    "        List of symbol names\n",
    "    \"\"\"\n",
    "    symbols = []\n",
    "    for item in session_path.iterdir():\n",
    "        if item.is_dir() and (item / \"trades.jsonl\").exists():\n",
    "            symbols.append(item.name)\n",
    "    return sorted(symbols)\n",
    "\n",
    "\n",
    "def list_available_sessions(data_root: Path) -> List[str]:\n",
    "    \"\"\"\n",
    "    List all available session directories.\n",
    "    \n",
    "    Args:\n",
    "        data_root: Root data directory\n",
    "    \n",
    "    Returns:\n",
    "        List of session names\n",
    "    \"\"\"\n",
    "    sessions_dir = data_root / \"sessions\" if (data_root / \"sessions\").exists() else data_root\n",
    "    sessions = []\n",
    "    for item in sessions_dir.iterdir():\n",
    "        if item.is_dir():\n",
    "            sessions.append(item.name)\n",
    "    return sorted(sessions)\n",
    "\n",
    "\n",
    "def sample_data_head(\n",
    "    session_path: Path,\n",
    "    symbol: str,\n",
    "    data_type: str = \"trades\",\n",
    "    n: int = 5\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Quick preview of data file contents.\n",
    "    \n",
    "    Args:\n",
    "        session_path: Path to session directory\n",
    "        symbol: Symbol name\n",
    "        data_type: \"trades\" or \"depth\"\n",
    "        n: Number of rows to show\n",
    "    \"\"\"\n",
    "    file_path = session_path / symbol / f\"{data_type}.jsonl\"\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Exists: {file_path.exists()}\")\n",
    "    if file_path.exists():\n",
    "        loader = FlexibleDataLoader(file_path)\n",
    "        df = loader.load(nrows=n)\n",
    "        loader.describe_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DISCOVER AVAILABLE DATA ===\n",
    "# Uncomment to explore your data\n",
    "\n",
    "# session_path = DATA_ROOT / SESSION_NAME\n",
    "# available_symbols = discover_session_symbols(session_path)\n",
    "# print(f\"Available symbols: {available_symbols}\")\n",
    "#\n",
    "# # Preview sample data\n",
    "# sample_data_head(session_path, available_symbols[0], \"trades\", n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Research Workflow Template\n",
    "\n",
    "Follow this workflow for arbitrage research:\n",
    "\n",
    "### Step 1: Data Discovery\n",
    "```python\n",
    "# List sessions and symbols\n",
    "sessions = list_available_sessions(DATA_ROOT)\n",
    "symbols = discover_session_symbols(DATA_ROOT / sessions[0])\n",
    "```\n",
    "\n",
    "### Step 2: Load and Inspect Data\n",
    "```python\n",
    "# Load data for selected symbols\n",
    "data_dict = {}\n",
    "for symbol in SYMBOLS:\n",
    "    data_dict[symbol] = load_symbol_data(session_path, symbol, \"trades\")\n",
    "```\n",
    "\n",
    "### Step 3: Align Data\n",
    "```python\n",
    "# Align to common time grid\n",
    "aligner = MultiSymbolAligner(resample_freq=\"100ms\")\n",
    "aligned_prices = aligner.align(data_dict)\n",
    "```\n",
    "\n",
    "### Step 4: Calculate Spreads\n",
    "```python\n",
    "# Calculate your arbitrage spread\n",
    "spread = calculate_triangular_spread(aligned_prices, ...)  # Implement this\n",
    "```\n",
    "\n",
    "### Step 5: Analyze and Visualize\n",
    "```python\n",
    "# Visualize spread distribution\n",
    "viz = ArbVisualizer()\n",
    "viz.plot_spread_distribution(spread)\n",
    "```\n",
    "\n",
    "### Step 6: Backtest with VectorBT\n",
    "```python\n",
    "# Run backtest\n",
    "vbt_portfolio = VBTArbPortfolio(aligned_prices)\n",
    "portfolio = vbt_portfolio.run_spread_backtest(spread, entries, exits)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === YOUR RESEARCH STARTS HERE ===\n",
    "# Use the utilities above to conduct your arbitrage research\n",
    "\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
