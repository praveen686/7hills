{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantLaxmi — Arb Observables Analysis\n",
    "\n",
    "**Session**: Profile-1 Crypto (2-hour certified)\n",
    "\n",
    "**Purpose**: Discover structural arbitrage signals that survive fees + latency\n",
    "\n",
    "**Status**: SCAFFOLDING ONLY - DO NOT EXECUTE UNTIL SESSION COMPLETE\n",
    "\n",
    "---\n",
    "\n",
    "## Rule Zero\n",
    "You are not allowed to invent conclusions tonight.\n",
    "Tonight is about preparing the ground so that tomorrow's analysis is boring, deterministic, and correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants (Frozen)\n",
    "\n",
    "| Parameter | Value | Notes |\n",
    "|-----------|-------|-------|\n",
    "| Taker fee | 0.001 (0.1%) | Binance spot default |\n",
    "| Latency windows | 20ms, 50ms, 100ms | Sensitivity test |\n",
    "| Quote age cutoff | 200ms | Hard filter |\n",
    "| Price exponent | -2 | Binance mantissa |\n",
    "| Qty exponent | -8 | Binance mantissa |\n",
    "\n",
    "### Profile-1 Symbols\n",
    "**USDT pairs**: BTCUSDT, ETHUSDT, BNBUSDT, SOLUSDT, XRPUSDT\n",
    "\n",
    "**Cross pairs**: ETHBTC, BNBBTC, SOLBTC\n",
    "\n",
    "### Triangle Definitions\n",
    "| Triangle | Leg A | Leg B | Leg C |\n",
    "|----------|-------|-------|-------|\n",
    "| ETH-BTC | BTCUSDT | ETHBTC | ETHUSDT |\n",
    "| BNB-BTC | BTCUSDT | BNBBTC | BNBUSDT |\n",
    "| SOL-BTC | BTCUSDT | SOLBTC | SOLUSDT |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Preconditions Check\n",
    "\n",
    "Before computing anything, verify:\n",
    "- [ ] Session is certified\n",
    "- [ ] All symbols present for entire interval\n",
    "- [ ] No symbol downgrade\n",
    "- [ ] Depth + trades both available\n",
    "- [ ] Timestamps monotonic per symbol\n",
    "\n",
    "**If any fail → ABORT ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 0. Preconditions Check\nimport json\nfrom pathlib import Path\n\nSESSION_DIR = Path(\"/home/isoula/7hills/QuantLaxmi/data/sessions/_sealed/profile1_2h_20260122_2224\")\n\n# Load and verify manifest\nwith open(SESSION_DIR / \"session_manifest.json\") as f:\n    manifest = json.load(f)\n\nprint(\"Session ID:\", manifest[\"session_id\"])\nprint(\"Certified:\", manifest[\"determinism\"][\"certified\"])\nprint(\"All symbols clean:\", manifest[\"determinism\"][\"all_symbols_clean\"])\nprint(\"Semantics:\", manifest[\"determinism\"][\"semantics\"])\nprint(\"Duration:\", f\"{manifest['duration_secs']:.1f}s ({manifest['duration_secs']/3600:.2f}h)\")\nprint(\"\\nSymbols:\", manifest[\"symbols\"])\n\n# Verify Triangle A symbols present\ntriangle_a_symbols = [\"BTCUSDT\", \"ETHUSDT\", \"ETHBTC\"]\nfor sym in triangle_a_symbols:\n    if sym not in manifest[\"symbols\"]:\n        raise ValueError(f\"ABORT: Missing symbol {sym}\")\n    capture = next(c for c in manifest[\"captures\"] if c[\"symbol\"] == sym)\n    print(f\"\\n{sym}:\")\n    print(f\"  Depth events: {capture['events_written']:,}\")\n    print(f\"  Trades: {capture['trades_written']:,}\")\n    print(f\"  Hash: {capture['depth_hash'][:16]}...\")\n\nprint(\"\\n✓ All preconditions satisfied for Triangle A\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Loading & Time Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 1. Data Loading & Time Alignment for Triangle A\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime, timedelta\nfrom dateutil import parser as dtparser\n\ndef load_depth_quotes(session_dir: Path, symbol: str) -> pd.DataFrame:\n    \"\"\"Load depth.jsonl and extract best bid/ask with timestamps.\"\"\"\n    depth_file = session_dir / symbol / \"depth.jsonl\"\n    \n    records = []\n    with open(depth_file) as f:\n        for line in f:\n            rec = json.loads(line)\n            ts = dtparser.isoparse(rec[\"ts\"])\n            \n            # Extract best bid/ask from depth\n            # bids and asks are lists of [price_mantissa, qty_mantissa]\n            bids = rec.get(\"bids\", [])\n            asks = rec.get(\"asks\", [])\n            \n            if not bids or not asks:\n                continue\n            \n            price_exp = rec.get(\"price_exponent\", -2)\n            \n            # Best bid = highest bid, best ask = lowest ask\n            best_bid = bids[0][0] * (10 ** price_exp)\n            best_ask = asks[0][0] * (10 ** price_exp)\n            \n            records.append({\n                \"ts\": ts,\n                \"bid\": best_bid,\n                \"ask\": best_ask\n            })\n    \n    df = pd.DataFrame(records)\n    df = df.sort_values(\"ts\").reset_index(drop=True)\n    df[\"ts_ns\"] = df[\"ts\"].astype(\"int64\")\n    return df\n\n# Load all three legs\nprint(\"Loading BTCUSDT depth...\")\nbtcusdt = load_depth_quotes(SESSION_DIR, \"BTCUSDT\")\nprint(f\"  {len(btcusdt):,} quotes, {btcusdt['ts'].min()} to {btcusdt['ts'].max()}\")\n\nprint(\"Loading ETHUSDT depth...\")\nethusdt = load_depth_quotes(SESSION_DIR, \"ETHUSDT\")\nprint(f\"  {len(ethusdt):,} quotes, {ethusdt['ts'].min()} to {ethusdt['ts'].max()}\")\n\nprint(\"Loading ETHBTC depth...\")\nethbtc = load_depth_quotes(SESSION_DIR, \"ETHBTC\")\nprint(f\"  {len(ethbtc):,} quotes, {ethbtc['ts'].min()} to {ethbtc['ts'].max()}\")"
  },
  {
   "cell_type": "code",
   "source": "# 1b. Build Global Timeline with 200ms Staleness Cap\n\nMAX_STALENESS_MS = 200\nMAX_STALENESS_NS = MAX_STALENESS_MS * 1_000_000\n\ndef build_aligned_quotes(dfs: dict, max_staleness_ns: int) -> pd.DataFrame:\n    \"\"\"\n    Build global timeline from union of all quote timestamps.\n    Forward-fill each leg with staleness cap.\n    Drop rows where any leg exceeds staleness.\n    \"\"\"\n    # Collect all unique timestamps\n    all_ts = set()\n    for name, df in dfs.items():\n        all_ts.update(df[\"ts_ns\"].tolist())\n    \n    global_ts = sorted(all_ts)\n    print(f\"Global timeline: {len(global_ts):,} unique timestamps\")\n    \n    # Build result dataframe\n    result = pd.DataFrame({\"ts_ns\": global_ts})\n    \n    for name, df in dfs.items():\n        # Merge and forward-fill\n        df_subset = df[[\"ts_ns\", \"bid\", \"ask\"]].copy()\n        df_subset = df_subset.rename(columns={\"bid\": f\"{name}_bid\", \"ask\": f\"{name}_ask\"})\n        df_subset[f\"{name}_quote_ts\"] = df_subset[\"ts_ns\"]\n        \n        result = pd.merge_asof(\n            result.sort_values(\"ts_ns\"),\n            df_subset.sort_values(\"ts_ns\"),\n            on=\"ts_ns\",\n            direction=\"backward\"\n        )\n    \n    # Compute staleness for each leg\n    for name in dfs.keys():\n        result[f\"{name}_staleness\"] = result[\"ts_ns\"] - result[f\"{name}_quote_ts\"]\n    \n    # Filter: drop rows where any leg exceeds staleness cap\n    mask = pd.Series(True, index=result.index)\n    for name in dfs.keys():\n        mask &= (result[f\"{name}_staleness\"] <= max_staleness_ns)\n    \n    result_clean = result[mask].copy()\n    \n    dropped = len(result) - len(result_clean)\n    print(f\"Dropped {dropped:,} rows ({100*dropped/len(result):.2f}%) due to staleness > {MAX_STALENESS_MS}ms\")\n    \n    return result_clean\n\n# Build aligned quotes\naligned = build_aligned_quotes(\n    {\"btcusdt\": btcusdt, \"ethusdt\": ethusdt, \"ethbtc\": ethbtc},\n    MAX_STALENESS_NS\n)\n\nprint(f\"\\nAligned dataset: {len(aligned):,} valid quote snapshots\")\nprint(f\"Time range: {pd.to_datetime(aligned['ts_ns'].min())} to {pd.to_datetime(aligned['ts_ns'].max())}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 2. Triangle A Residuals — Gross (No Fees)\n#\n# Triangle A: BTC-ETH-USDT\n# Legs: BTCUSDT, ETHUSDT, ETHBTC\n#\n# Direction CW (USDT → BTC → ETH → USDT):\n#   Buy BTC with USDT (pay ask), Sell BTC for ETH (get bid on ETHBTC), Sell ETH for USDT (get bid)\n#   ε_cw = log(ETHUSDT_bid) - log(BTCUSDT_ask) - log(ETHBTC_ask)\n#\n# Direction CCW (USDT → ETH → BTC → USDT):\n#   Buy ETH with USDT (pay ask), Sell ETH for BTC (get bid on ETHBTC), Sell BTC for USDT (get bid)\n#   ε_ccw = log(BTCUSDT_bid) + log(ETHBTC_bid) - log(ETHUSDT_ask)\n\n# Compute residuals\naligned[\"epsilon_cw\"] = (\n    np.log(aligned[\"ethusdt_bid\"]) \n    - np.log(aligned[\"btcusdt_ask\"]) \n    - np.log(aligned[\"ethbtc_ask\"])\n)\n\naligned[\"epsilon_ccw\"] = (\n    np.log(aligned[\"btcusdt_bid\"]) \n    + np.log(aligned[\"ethbtc_bid\"]) \n    - np.log(aligned[\"ethusdt_ask\"])\n)\n\n# Basic sanity check\nprint(\"Residual Statistics (log scale):\")\nprint(f\"\\nε_cw:  mean={aligned['epsilon_cw'].mean():.6f}, std={aligned['epsilon_cw'].std():.6f}\")\nprint(f\"       min={aligned['epsilon_cw'].min():.6f}, max={aligned['epsilon_cw'].max():.6f}\")\nprint(f\"\\nε_ccw: mean={aligned['epsilon_ccw'].mean():.6f}, std={aligned['epsilon_ccw'].std():.6f}\")\nprint(f\"       min={aligned['epsilon_ccw'].min():.6f}, max={aligned['epsilon_ccw'].max():.6f}\")\n\n# Convert to basis points for intuition\nprint(f\"\\nIn basis points (1 bp = 0.0001):\")\nprint(f\"ε_cw  range: [{aligned['epsilon_cw'].min()*10000:.1f}, {aligned['epsilon_cw'].max()*10000:.1f}] bp\")\nprint(f\"ε_ccw range: [{aligned['epsilon_ccw'].min()*10000:.1f}, {aligned['epsilon_ccw'].max()*10000:.1f}] bp\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Triangle Residuals Gross - DO NOT EXECUTE UNTIL SESSION COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Triangle Residuals — Fee Adjusted\n",
    "\n",
    "ε_net = ε_gross - 3f (where f = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Fee Adjusted - DO NOT EXECUTE UNTIL SESSION COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Latency Penalty Sensitivity\n",
    "\n",
    "Test with T_exec = 20ms, 50ms, 100ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Latency Penalty - DO NOT EXECUTE UNTIL SESSION COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 5. Triangle A Statistics — Minimal Required Metrics\n\ndef compute_run_durations(series: pd.Series, ts_ns: pd.Series, positive: bool = True) -> dict:\n    \"\"\"\n    Compute contiguous run durations where condition is met.\n    Returns median, p90, max durations in milliseconds.\n    \"\"\"\n    if positive:\n        mask = series > 0\n    else:\n        mask = series < 0\n    \n    # Find run boundaries\n    run_starts = []\n    run_ends = []\n    in_run = False\n    \n    for i in range(len(mask)):\n        if mask.iloc[i] and not in_run:\n            run_starts.append(i)\n            in_run = True\n        elif not mask.iloc[i] and in_run:\n            run_ends.append(i - 1)\n            in_run = False\n    \n    if in_run:\n        run_ends.append(len(mask) - 1)\n    \n    if not run_starts:\n        return {\"median_ms\": 0, \"p90_ms\": 0, \"max_ms\": 0, \"count\": 0}\n    \n    # Compute durations in ms\n    durations_ms = []\n    for start, end in zip(run_starts, run_ends):\n        duration_ns = ts_ns.iloc[end] - ts_ns.iloc[start]\n        durations_ms.append(duration_ns / 1_000_000)\n    \n    durations_ms = np.array(durations_ms)\n    \n    return {\n        \"median_ms\": np.median(durations_ms),\n        \"p90_ms\": np.percentile(durations_ms, 90),\n        \"max_ms\": np.max(durations_ms),\n        \"count\": len(durations_ms)\n    }\n\n# Compute statistics for both directions\nprint(\"=\" * 60)\nprint(\"TRIANGLE A (BTC-ETH-USDT) — STATISTICS SUMMARY\")\nprint(\"=\" * 60)\n\nfor direction, col in [(\"CW\", \"epsilon_cw\"), (\"CCW\", \"epsilon_ccw\")]:\n    eps = aligned[col]\n    \n    # Hit rate (gross positive)\n    hr = (eps > 0).mean()\n    \n    # P99 and max\n    p99 = np.percentile(eps, 99)\n    eps_max = eps.max()\n    \n    # Run durations\n    runs = compute_run_durations(eps, aligned[\"ts_ns\"], positive=True)\n    \n    # Spread-conditioned hit rate\n    tight_mask = aligned[\"spread_sum\"] <= spread_sum_p50\n    hr_tight = (eps[tight_mask] > 0).mean() if tight_mask.sum() > 0 else 0\n    \n    print(f\"\\n{direction} Direction:\")\n    print(f\"  HR (gross):        {hr*100:.4f}%\")\n    print(f\"  HR (tight spread): {hr_tight*100:.4f}%\")\n    print(f\"  P99 residual:      {p99*10000:.2f} bp\")\n    print(f\"  Max residual:      {eps_max*10000:.2f} bp\")\n    print(f\"  Positive runs:     {runs['count']:,}\")\n    print(f\"    Median duration: {runs['median_ms']:.1f} ms\")\n    print(f\"    P90 duration:    {runs['p90_ms']:.1f} ms\")\n    print(f\"    Max duration:    {runs['max_ms']:.1f} ms\")\n\nprint(\"\\n\" + \"=\" * 60)\n\n# Sanity check: are both always positive? (would indicate bug)\nboth_positive = ((aligned[\"epsilon_cw\"] > 0) & (aligned[\"epsilon_ccw\"] > 0)).mean()\nprint(f\"\\nSanity check: Both CW and CCW positive simultaneously: {both_positive*100:.4f}%\")\nif both_positive > 0.5:\n    print(\"⚠️  WARNING: If both directions often positive, check alignment logic!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Health Metrics - DO NOT EXECUTE UNTIL SESSION COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 6. Spread-Residual Coupling — Context Series\n\n# Compute relative spread for each leg\naligned[\"btcusdt_spread\"] = (aligned[\"btcusdt_ask\"] - aligned[\"btcusdt_bid\"]) / ((aligned[\"btcusdt_ask\"] + aligned[\"btcusdt_bid\"]) / 2)\naligned[\"ethusdt_spread\"] = (aligned[\"ethusdt_ask\"] - aligned[\"ethusdt_bid\"]) / ((aligned[\"ethusdt_ask\"] + aligned[\"ethusdt_bid\"]) / 2)\naligned[\"ethbtc_spread\"] = (aligned[\"ethbtc_ask\"] - aligned[\"ethbtc_bid\"]) / ((aligned[\"ethbtc_ask\"] + aligned[\"ethbtc_bid\"]) / 2)\n\n# Total spread (sum of relative spreads)\naligned[\"spread_sum\"] = aligned[\"btcusdt_spread\"] + aligned[\"ethusdt_spread\"] + aligned[\"ethbtc_spread\"]\n\nprint(\"Spread Statistics (relative):\")\nprint(f\"\\nBTCUSDT: mean={aligned['btcusdt_spread'].mean()*10000:.2f} bp, p50={aligned['btcusdt_spread'].median()*10000:.2f} bp\")\nprint(f\"ETHUSDT: mean={aligned['ethusdt_spread'].mean()*10000:.2f} bp, p50={aligned['ethusdt_spread'].median()*10000:.2f} bp\")\nprint(f\"ETHBTC:  mean={aligned['ethbtc_spread'].mean()*10000:.2f} bp, p50={aligned['ethbtc_spread'].median()*10000:.2f} bp\")\nprint(f\"\\nSpread Sum: mean={aligned['spread_sum'].mean()*10000:.2f} bp, p50={aligned['spread_sum'].median()*10000:.2f} bp\")\n\n# Compute spread_sum percentiles for later conditioning\nspread_sum_p50 = aligned[\"spread_sum\"].median()\nprint(f\"\\nSpread Sum p50 threshold: {spread_sum_p50*10000:.2f} bp\")"
  },
  {
   "cell_type": "code",
   "source": "# Plot 3: Residual vs Spread_Sum Scatter\n\n# Use max of cw/ccw for y-axis\naligned[\"epsilon_max\"] = aligned[[\"epsilon_cw\", \"epsilon_ccw\"]].max(axis=1)\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Subsample for scatter (every 50th point)\nscatter_data = aligned.iloc[::50].copy()\n\nax.scatter(\n    scatter_data[\"spread_sum\"] * 10000, \n    scatter_data[\"epsilon_max\"] * 10000,\n    alpha=0.3, s=5\n)\n\nax.axhline(y=0, color='r', linestyle='--', linewidth=1, label='ε=0')\nax.axvline(x=spread_sum_p50 * 10000, color='g', linestyle='--', linewidth=1, label=f'spread_sum p50 ({spread_sum_p50*10000:.1f} bp)')\n\nax.set_xlabel(\"Spread Sum (basis points)\")\nax.set_ylabel(\"max(ε_cw, ε_ccw) (basis points)\")\nax.set_title(\"Triangle A: Residual vs Total Spread\")\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Plot 3: Residual vs spread scatter — check if positives require wide spreads\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Plot 2: Residual Histograms (cw and ccw separately)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# CW histogram\naxes[0].hist(aligned[\"epsilon_cw\"] * 10000, bins=100, alpha=0.7, edgecolor='black', linewidth=0.5)\naxes[0].axvline(x=0, color='r', linestyle='--', linewidth=1, label='zero')\naxes[0].set_xlabel(\"ε_cw (basis points)\")\naxes[0].set_ylabel(\"Frequency\")\naxes[0].set_title(\"Distribution of ε_cw (Clockwise)\")\naxes[0].legend()\n\n# CCW histogram\naxes[1].hist(aligned[\"epsilon_ccw\"] * 10000, bins=100, alpha=0.7, edgecolor='black', linewidth=0.5, color='orange')\naxes[1].axvline(x=0, color='r', linestyle='--', linewidth=1, label='zero')\naxes[1].set_xlabel(\"ε_ccw (basis points)\")\naxes[1].set_ylabel(\"Frequency\")\naxes[1].set_title(\"Distribution of ε_ccw (Counter-Clockwise)\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Plot 2: Residual histograms — check tail behavior and typical magnitude\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Final Summary Cell — To be filled after execution\n\nprint(\"=\" * 70)\nprint(\"TRIANGLE A FINAL REPORT\")\nprint(\"=\" * 70)\n\n# Hit rates\nhr_cw = (aligned[\"epsilon_cw\"] > 0).mean()\nhr_ccw = (aligned[\"epsilon_ccw\"] > 0).mean()\n\ntight_mask = aligned[\"spread_sum\"] <= spread_sum_p50\nhr_cw_tight = (aligned[\"epsilon_cw\"][tight_mask] > 0).mean()\nhr_ccw_tight = (aligned[\"epsilon_ccw\"][tight_mask] > 0).mean()\n\n# P99\np99_cw = np.percentile(aligned[\"epsilon_cw\"], 99)\np99_ccw = np.percentile(aligned[\"epsilon_ccw\"], 99)\n\n# Max run durations\nruns_cw = compute_run_durations(aligned[\"epsilon_cw\"], aligned[\"ts_ns\"], positive=True)\nruns_ccw = compute_run_durations(aligned[\"epsilon_ccw\"], aligned[\"ts_ns\"], positive=True)\n\nprint(f\"\\nHR(cw):  {hr_cw*100:.4f}%\")\nprint(f\"HR(ccw): {hr_ccw*100:.4f}%\")\nprint(f\"\\np99(cw):  {p99_cw*10000:.2f} bp\")\nprint(f\"p99(ccw): {p99_ccw*10000:.2f} bp\")\nprint(f\"\\nMax run duration (cw):  {runs_cw['max_ms']:.1f} ms\")\nprint(f\"Max run duration (ccw): {runs_ccw['max_ms']:.1f} ms\")\n\n# Spread assessment\nwide_mask = aligned[\"spread_sum\"] > spread_sum_p50\nhr_cw_wide = (aligned[\"epsilon_cw\"][wide_mask] > 0).mean()\nhr_ccw_wide = (aligned[\"epsilon_ccw\"][wide_mask] > 0).mean()\n\nprint(f\"\\nSpread conditioning:\")\nprint(f\"  HR_tight(cw):  {hr_cw_tight*100:.4f}%  |  HR_wide(cw):  {hr_cw_wide*100:.4f}%\")\nprint(f\"  HR_tight(ccw): {hr_ccw_tight*100:.4f}%  |  HR_wide(ccw): {hr_ccw_wide*100:.4f}%\")\n\n# Determine spread condition\nif hr_cw_tight > hr_cw_wide:\n    spread_cond_cw = \"low/normal\"\nelif hr_cw_tight < hr_cw_wide * 0.5:\n    spread_cond_cw = \"high (wide spreads)\"\nelse:\n    spread_cond_cw = \"normal (no strong dependency)\"\n\nif hr_ccw_tight > hr_ccw_wide:\n    spread_cond_ccw = \"low/normal\"\nelif hr_ccw_tight < hr_ccw_wide * 0.5:\n    spread_cond_ccw = \"high (wide spreads)\"\nelse:\n    spread_cond_ccw = \"normal (no strong dependency)\"\n\nprint(f\"\\n→ Positive residuals (CW) occur mostly when spread_sum is: {spread_cond_cw}\")\nprint(f\"→ Positive residuals (CCW) occur mostly when spread_sum is: {spread_cond_ccw}\")\n\nprint(\"\\n\" + \"=\" * 70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Spread Coupling - DO NOT EXECUTE UNTIL SESSION COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Stat-Arb Spread Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Stat-Arb - DO NOT EXECUTE UNTIL SESSION COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary (Fill after 02:00 IST)\n",
    "\n",
    "1. Which triangles ever go gross-positive: [TBD]\n",
    "2. Typical duration of positive windows: [TBD]\n",
    "3. Whether cw/ccw are symmetric: [TBD]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}